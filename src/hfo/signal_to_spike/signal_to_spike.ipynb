{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Signal To Spike Conversion** - Pre-Processing of the SEEG Signal (2/2)\n",
    "This notebook presents the **pre-processing stage 2** the SEEG signal goes through before being fed to the SNN. The pre-processing stages are as follows:\n",
    "1. **Filtering**: The SEEG signal is bandpass filtered to remove noise and artifacts. The bandpass filter is designed using the Butterworth filter and, since we are working with *iEEG*, the signal is filtered in the ripples and FR bands. The co-occurrence of HFOs in both bands is an optimal prediction of post-surgical seizure freedom by defining an optimal \"HFO area\" or EZ zone.\n",
    "2. **Signal-to-Spike Conversion**: To interface and communicate with the silicon neurons in the SNN, the SEEG signal must be converted to spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check WD (change if necessary) and file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/monkin/Desktop/feup/thesis/thesis-lava/src/hfo/signal_to_spike\n"
     ]
    }
   ],
   "source": [
    "# Show current directory\n",
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)\n",
    "\n",
    "# Check if the current WD is the file location\n",
    "if \"/src/hfo/signal_to_spike\" not in os.getcwd():\n",
    "    # Set working directory to this file location\n",
    "    file_location = f\"{os.getcwd()}/thesis-lava/src/hfo/signal_to_spike\"\n",
    "    print(\"File Location: \", file_location)\n",
    "\n",
    "    # Change the current working Directory\n",
    "    os.chdir(file_location)\n",
    "\n",
    "    # New Working Directory\n",
    "    print(\"New Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "\n",
    "Right now, we have the filtered SEEG signal in both the ripple and FR bands. The next step is to convert the signal to spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first load the filtered SEEG signal and the corresponding markers\n",
    "This notebook only converts 1 SEEG channel to spikes. Therefore, the `.npy` file must contain a single channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the `INPUT_FOLDER` and `RESULTS_FOLDER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREFUL WITH THIS FOLDER TO NOT OVERWRITE THE FILES\n",
    "INPUT_FOLDER = \"../subset/results/seeg_filtered_subset_90-119_segment1000_300\"\n",
    "RESULTS_FOLDER = \"results/custom_subset_90-119_segment1000_300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple Band SEEG Shape: (245760,).\n",
      "Preview: [1.84829940e-04 1.37975809e-03 3.92964380e-03 ... 1.23691538e+00\n",
      " 7.54000855e-01 1.73992494e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from utils.io import preview_np_array\n",
    "\n",
    "# Load the filtered seeg signal in the ripple band\n",
    "ripple_seeg_file_name = f\"{INPUT_FOLDER}/ripple_band.npy\"\n",
    "ripple_band_seeg = np.load(f\"{ripple_seeg_file_name}\")\n",
    "\n",
    "# Remove the extra inner dimension\n",
    "ripple_band_seeg = np.squeeze(ripple_band_seeg)\n",
    "\n",
    "preview_np_array(ripple_band_seeg, \"Ripple Band SEEG\", edge_items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR Band SEEG Shape: (245760,).\n",
      "Preview: [ 0.00095524  0.00310525 -0.00478473 ... -0.49596476 -0.2753618\n",
      "  0.28661303]\n"
     ]
    }
   ],
   "source": [
    "# Load the filtered seeg signal in the fast ripple band\n",
    "fr_seeg_file_name = f\"{INPUT_FOLDER}/fr_band.npy\"\n",
    "fr_band_seeg = np.load(f\"{fr_seeg_file_name}\")\n",
    "\n",
    "# Remove the extra inner dimension\n",
    "fr_band_seeg = np.squeeze(fr_band_seeg)\n",
    "\n",
    "preview_np_array(fr_band_seeg, \"FR Band SEEG\", edge_items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ripple_markers Shape: (115,).\n",
      "Preview: [('Spike+Ripple',   1000.  , 0.) ('Spike+Fast-Ripple',   3454.59, 0.)\n",
      " ('Ripple+Fast-Ripple',   4134.77, 0.) ...\n",
      " ('Spike+Ripple+Fast-Ripple', 115019.  , 0.)\n",
      " ('Spike+Ripple', 116517.  , 0.) ('Fast-Ripple', 119000.  , 0.)]\n"
     ]
    }
   ],
   "source": [
    "# Load the annotated events (For Ripples)\n",
    "ripple_markers_file_name = f\"{INPUT_FOLDER}/markers_ripple_band.npy\"\n",
    "ripple_markers = np.load(f\"{ripple_markers_file_name}\")\n",
    "\n",
    "# Remove the extra inner dimension\n",
    "ripple_markers = np.squeeze(ripple_markers)\n",
    "\n",
    "preview_np_array(ripple_markers, \"ripple_markers\", edge_items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr_markers Shape: (114,).\n",
      "Preview: [('Fast-Ripple',   1000.  , 0.) ('Spike+Fast-Ripple',   3454.59, 0.)\n",
      " ('Ripple+Fast-Ripple',   4134.77, 0.) ...\n",
      " ('Spike+Ripple+Fast-Ripple', 115019.  , 0.)\n",
      " ('Ripple+Fast-Ripple', 116656.  , 0.) ('Fast-Ripple', 119000.  , 0.)]\n"
     ]
    }
   ],
   "source": [
    "# Load the annotated events (For Fast Ripples)\n",
    "fr_markers_file_name = f\"{INPUT_FOLDER}/markers_fr_band.npy\"\n",
    "fr_markers = np.load(f\"{fr_markers_file_name}\")\n",
    "\n",
    "# Remove the extra inner dimension\n",
    "fr_markers = np.squeeze(fr_markers)\n",
    "\n",
    "preview_np_array(fr_markers, \"fr_markers\", edge_items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Global Parameters of the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This could be in the utils?\n",
    "\n",
    "sampling_rate = 2048    # 2048 Hz\n",
    "input_duration = 120 * (10**3)    # 120000 ms or 120 seconds\n",
    "num_samples = ripple_band_seeg.shape[0]    # 2048 * 120 = 245760\n",
    "\n",
    "x_step = 1/sampling_rate * (10**3)  # 0.48828125 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal-to-Spike Conversion\n",
    "The signal can be converted to spikes in different ways. First, we will try a method where **two spike trains are generated from the filtered signal**:\n",
    "- **UP Spike Train**: The spikes are generated based on an increase of the signal's amplitude. The spikes are generated when the signal crosses a certain threshold defined by `threshold_up`.\n",
    "- **DOWN Spike Train**: The spikes are generated based on a decrease of the signal's amplitude. The spikes are generated when the signal crosses a certain threshold defined by `threshold_down`.\n",
    "\n",
    "The spike trains are generated by comparing the amount of change in the signal since the last time a spike was generated (UP or DOWN). If the positive/negative amplitude change is greater than the defined threshold, the algorithm stores the current timestep in the respective spike train and takes the new amplitude as the reference for the next comparison.\n",
    "\n",
    "Another important aspect of this algorithm is to model the time that silicon neurons need before they can generate another spike. Both in hardware and software, we call this time `refractory_period`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurable Parameters for the Signal-to-Spike Conversion\n",
    "- `threshold_up`: The threshold for the UP spike train.\n",
    "- `threshold_down`: The threshold for the DOWN spike train.\n",
    "\n",
    "The accuracy of this algorithm is heavily dependent on the choice of these parameters. To find the optimal values, we can perform a ***baseline detection*** to determine the optimal spike generation threshold automatically for the signal conversion.\n",
    "\n",
    "**As a first solution, we set these values manually to have a working prototype. Later, we will find the optimal values and compare the results of both methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables of the Signal to Spike Conversion Manually\n",
    "ripple_threshold_up = 5   # Threshold for the UP spike detection (in μV)\n",
    "ripple_threshold_down = -5 # Threshold for the DOWN spike detection (in μV)\n",
    "\n",
    "fr_threshold_up = 3   # Threshold for the UP spike detection (in μV)\n",
    "fr_threshold_down = -3 # Threshold for the DOWN spike detection (in μV)\n",
    "# TODO: Change this thresholds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plot for the HFO detection\n",
    "# bokeh docs: https://docs.bokeh.org/en/2.4.1/docs/first_steps/first_steps_1.html\n",
    "\n",
    "from utils.line_plot import create_fig  # Import the function to create the figure\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "# Define the x and y values\n",
    "# Should the first input start at 0 or x_step?\n",
    "# TODO: is it okay to create a range with floats?\n",
    "x = [val for val in np.arange(x_step, input_duration + x_step, x_step)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple UP Spike Train shape:  (1289,) Preview:  [  1004.8828125    1006.34765625   1016.6015625    1017.578125\n",
      "   1027.34375    ... 118970.703125   118982.421875   118990.72265625\n",
      " 119005.859375   119009.27734375]\n",
      "Ripple DOWN Spike Train shape:  (1283,) Preview:  [  1001.953125     1011.23046875   1013.18359375   1021.484375\n",
      "   1022.4609375  ... 118964.35546875 118974.609375   118986.328125\n",
      " 118996.09375    119007.8125    ]\n"
     ]
    }
   ],
   "source": [
    "from hfo.signal_to_spike.signal_to_spike import signal_to_spike, SignalToSpikeParameters\n",
    "\n",
    "# Convert the filtered ripple signal to spikes\n",
    "ripple_spike_trains = signal_to_spike(\n",
    "    SignalToSpikeParameters(\n",
    "        signal=ripple_band_seeg, times=np.array(x),\n",
    "        threshold_up=ripple_threshold_up, threshold_down=ripple_threshold_down,\n",
    "        # refractory_period=0.002, interpolation_factor=1\n",
    "        )\n",
    ")\n",
    "\n",
    "np.set_printoptions(edgeitems=5)\n",
    "print(\"Ripple UP Spike Train shape: \", ripple_spike_trains.up.shape, \"Preview: \", ripple_spike_trains.up)\n",
    "print(\"Ripple DOWN Spike Train shape: \", ripple_spike_trains.down.shape, \"Preview: \", ripple_spike_trains.down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast Ripple UP Spike Train shape:  (1647,) Preview:  [  1001.953125     1002.44140625   1005.37109375   1005.859375\n",
      "   1008.30078125 ... 119008.30078125 119008.7890625  119012.20703125\n",
      " 119015.13671875 119015.625     ]\n",
      "Fast Ripple DOWN Spike Train shape:  (1614,) Preview:  [  1000.9765625    1003.90625      1006.8359375    1007.32421875\n",
      "   1010.7421875  ... 119006.8359375  119010.25390625 119013.671875\n",
      " 119014.16015625 119016.6015625 ]\n"
     ]
    }
   ],
   "source": [
    "# Convert the filtered FR signal to spikes\n",
    "fr_spike_trains = signal_to_spike(\n",
    "    SignalToSpikeParameters(\n",
    "        signal=fr_band_seeg, times=np.array(x),\n",
    "        threshold_up=fr_threshold_up, threshold_down=fr_threshold_down,\n",
    "        # refractory_period=0.002, interpolation_factor=1   # TODO: Add refractory period\n",
    "        )\n",
    ")\n",
    "\n",
    "np.set_printoptions(edgeitems=5)\n",
    "print(\"Fast Ripple UP Spike Train shape: \", fr_spike_trains.up.shape, \"Preview: \", fr_spike_trains.up)\n",
    "print(\"Fast Ripple DOWN Spike Train shape: \", fr_spike_trains.down.shape, \"Preview: \", fr_spike_trains.down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Spike Trains\n",
    "Let's plot the generated spike trains via a raster plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.raster_plot import create_raster_fig\n",
    "\n",
    "# ------------------------------------------------------------------------------- #\n",
    "# ------- Create the raster plot for the Ripple UP and DOWN spike trains -------- #\n",
    "# ------------------------------------------------------------------------------- #\n",
    "\n",
    "# Create a list containing the x values for the raster plot.\n",
    "ripple_raster_x = np.concatenate((ripple_spike_trains.up, ripple_spike_trains.down), axis=0)\n",
    "\n",
    "# Create a list containing the y values for the raster plot.\n",
    "# The UP spike train will be represented by 1s and the DOWN spike train by 0s\n",
    "ripple_raster_y = [1 for _ in range(len(ripple_spike_trains.up))] + [0 for _ in range(len(ripple_spike_trains.down))]\n",
    "\n",
    "ripple_train_raster = create_raster_fig(\"Ripple UP and DOWN spike events\", \"Time (ms)\", \"Channel\", ripple_raster_x, ripple_raster_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bplt\n",
    "showRasterPlot = True\n",
    "\n",
    "# Plot the raster plot for the Ripple spike trains\n",
    "if showRasterPlot:\n",
    "    bplt.show(ripple_train_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------- #\n",
    "# ------- Create the raster plot for the Fast Ripple UP and DOWN spike trains -------- #\n",
    "# ------------------------------------------------------------------------------- #\n",
    "\n",
    "# Create a list containing the x values for the raster plot.\n",
    "fr_raster_x = np.concatenate((fr_spike_trains.up, fr_spike_trains.down), axis=0)\n",
    "\n",
    "# Create a list containing the y values for the raster plot.\n",
    "# The UP spike train will be represented by 1s and the DOWN spike train by 0s\n",
    "fr_raster_y = [1 for _ in range(len(fr_spike_trains.up))] + [0 for _ in range(len(fr_spike_trains.down))]\n",
    "\n",
    "fr_train_raster = create_raster_fig(\"Fast Ripple UP and DOWN spike events\", \"Time (ms)\", \"Channel\", fr_raster_x, fr_raster_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raster plot for the Fast Ripple spike trains\n",
    "if showRasterPlot:\n",
    "    bplt.show(fr_train_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Spike Trains to CSV Files for the Lava SNN\n",
    "\n",
    "We have successfully converted the SEEG signal to spikes. The next step is to feed these spikes to the SNN for Ripple and Fast Ripple detection.\n",
    "\n",
    "For this, we will create a file for each type of spike train (UP and DOWN). I'm not sure if we should join the spikes of both bands in a single file or keep them separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file with the spike train data\n",
    "import csv\n",
    "\n",
    "def write_spike_train_to_csv(file_name, spike_train, channel_idx):\n",
    "    \"\"\"\n",
    "    This function writes the spike train to a csv file.\n",
    "    @file_name (str): Name of the file to be created.\n",
    "    @spike_train (np.ndarray): Array with the spike train data.\n",
    "    @channel_idx (int): Index of the channel that generated the spike train. (According to the original data)\n",
    "    \"\"\"\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"time\", \"channel_idx\"])\n",
    "        for spike_time in spike_train:\n",
    "            writer.writerow([spike_time, channel_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_RIPPLE_CSV_FILES = True\n",
    "WRITE_FR_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ch_idx = -1    # TODO: Should we really send the channel?\n",
    "\n",
    "if WRITE_RIPPLE_CSV_FILES:\n",
    "    # Create the csv file for the Ripple UP spike train\n",
    "    ripple_up_file_name = f\"{RESULTS_FOLDER}/ripple_up_spike_train_5.csv\"\n",
    "    write_spike_train_to_csv(ripple_up_file_name, ripple_spike_trains.up, selected_ch_idx)\n",
    "\n",
    "    # Create the csv file for the Ripple DOWN spike train\n",
    "    ripple_down_file_name = f\"{RESULTS_FOLDER}/ripple_down_spike_train_-5.csv\"\n",
    "    write_spike_train_to_csv(ripple_down_file_name, ripple_spike_trains.down, selected_ch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_FR_CSV_FILES:\n",
    "    # Create the csv file for the Fast Ripple UP spike train\n",
    "    fr_up_file_name = f\"{RESULTS_FOLDER}/fr_up_spike_train_3.csv\"\n",
    "    write_spike_train_to_csv(fr_up_file_name, fr_spike_trains.up, selected_ch_idx)\n",
    "\n",
    "    # Create the csv file for the Fast Ripple DOWN spike train\n",
    "    fr_down_file_name = f\"{RESULTS_FOLDER}/fr_down_spike_train_-3.csv\"\n",
    "    write_spike_train_to_csv(fr_down_file_name, fr_spike_trains.down, selected_ch_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the input files for the SNN\n",
    "\n",
    "### Is the SNN going to detect the HFO events in windows? Or do we take it as a continous input?\n",
    "**If so**: The SNN is going to detect HFO events in windows. Therefore, the input to the network must be organized in windows of a certain size. The size of the window is a hyperparameter that can be tuned to improve the performance of the network.\n",
    "\n",
    "I think windowing makes more sense when we are learning with an ANN. Since we want real-time detection, feeding a continous input makes more sense.\n",
    "\n",
    "### Let's assume we do NOT need to window the input\n",
    "In this case, our input will simply be a continous stream of spikes. We can feed the spikes to the SNN in real-time. At each timestep, the SNN will receive 2 binary inputs (UP and DOWN spikes) indicating the presence of a spike in the respective spike train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snn_input:  (245760, 2) Preview: [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " ...\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array that will store the input (2D)\n",
    "snn_input = np.zeros((num_samples, 2))  # 2 columns: UP and DOWN spike trains\n",
    "\n",
    "# ---------------------------------------------------------------------------------- #\n",
    "# -------- Select the Spike Trains to be used as input for the SNN ----------------- #\n",
    "# ---------------------------------------------------------------------------------- #\n",
    "selected_up_spikes = ripple_spike_trains.up\n",
    "selected_down_spikes = ripple_spike_trains.down\n",
    "\n",
    "# Iterate the time steps of the recording and check if there are spikes in the selected spike trains at each timestep\n",
    "curr_up_idx = 0\n",
    "curr_down_idx = 0\n",
    "for (idx, time_step) in enumerate(x):\n",
    "    # Check if an UP spike occurs at this time step\n",
    "    if curr_up_idx < len(selected_up_spikes) and selected_up_spikes[curr_up_idx] <= time_step:\n",
    "        snn_input[idx][0] = 1   # Mark the UP spike in the input array\n",
    "        curr_up_idx += 1    # Move to the next spike in the UP spike train\n",
    "    # Check if a DOWN spike occurs at this time step\n",
    "    elif curr_down_idx < len(selected_down_spikes) and selected_down_spikes[curr_down_idx] <= time_step:\n",
    "        snn_input[idx][1] = 1   # Mark the DOWN spike in the input array\n",
    "        curr_down_idx += 1  # Move to the next spike in the DOWN spike train\n",
    "    \n",
    "    if curr_up_idx >= len(selected_up_spikes) and curr_down_idx >= len(selected_down_spikes):\n",
    "        # All the spikes have been added to the input array\n",
    "        break\n",
    "\n",
    "np.set_printoptions(edgeitems=5)\n",
    "print(\"snn_input: \", snn_input.shape, \"Preview:\", snn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the input array to a numpy file\n",
    "EXPORT_INPUT = True\n",
    "if EXPORT_INPUT:\n",
    "    input_file_name = f\"{RESULTS_FOLDER}/snn_input_ripple_5_-5.npy\"\n",
    "    np.save(input_file_name, snn_input)\n",
    "\n",
    "    EXPORT_INPUT_CSV = True\n",
    "    if EXPORT_INPUT_CSV:\n",
    "        # Export to CSV for visualization purposes\n",
    "        with open(f\"{RESULTS_FOLDER}/snn_input_ripple_5_-5.csv\", mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"time\", \"up_spike\", \"down_spike\"])\n",
    "            for (idx, time_step) in enumerate(x):\n",
    "                writer.writerow([time_step, snn_input[idx][0], snn_input[idx][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Ground Truth File for the SNN (Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the markers from the selected channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a target file for each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple Selected Channel Markers Shape: (115,).\n",
      "Preview: [('Spike+Ripple',   1000.  , 0.) ('Spike+Fast-Ripple',   3454.59, 0.)\n",
      " ('Ripple+Fast-Ripple',   4134.77, 0.)\n",
      " ('Ripple+Fast-Ripple',   5478.03, 0.)\n",
      " ('Spike+Fast-Ripple',   6539.06, 0.) ...\n",
      " ('Spike+Fast-Ripple', 113343.  , 0.) ('Ripple', 114551.  , 0.)\n",
      " ('Spike+Ripple+Fast-Ripple', 115019.  , 0.)\n",
      " ('Spike+Ripple', 116517.  , 0.) ('Fast-Ripple', 119000.  , 0.)]\n"
     ]
    }
   ],
   "source": [
    "# The target output for the SNN must have the same length as the input.\n",
    "ripple_target_np = np.zeros((num_samples))  # 1 column: 0/1 for the output classes (No Event, Ripple/Fast Ripple or both)\n",
    "# TODO: Could have more than 2 classes to differentiate the labels\n",
    "\n",
    "# Get the markers for the selected channel\n",
    "# Each marker has the following keys:   position, label, and duration\n",
    "ripple_selected_ch_markers = ripple_markers\n",
    "preview_np_array(ripple_selected_ch_markers, \"Ripple Selected Channel Markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR Selected Channel Markers Shape: (114,).\n",
      "Preview: [('Fast-Ripple',   1000.  , 0.) ('Spike+Fast-Ripple',   3454.59, 0.)\n",
      " ('Ripple+Fast-Ripple',   4134.77, 0.)\n",
      " ('Ripple+Fast-Ripple',   5478.03, 0.)\n",
      " ('Spike+Fast-Ripple',   6539.06, 0.) ...\n",
      " ('Spike+Fast-Ripple', 113343.  , 0.)\n",
      " ('Ripple+Fast-Ripple', 114293.  , 0.)\n",
      " ('Spike+Ripple+Fast-Ripple', 115019.  , 0.)\n",
      " ('Ripple+Fast-Ripple', 116656.  , 0.) ('Fast-Ripple', 119000.  , 0.)]\n"
     ]
    }
   ],
   "source": [
    "# The target output for the SNN must have the same length as the input.\n",
    "fr_target_np = np.zeros((num_samples))  # 1 column: 0/1 for the output classes (No Event, Ripple/Fast Ripple or both)\n",
    "\n",
    "fr_selected_ch_markers = fr_markers\n",
    "preview_np_array(fr_selected_ch_markers, \"FR Selected Channel Markers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to the format that the learnable SNN (Slayer) can read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the target numpy array with 1s where the HFOs are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.input import label_has_hfo_event\n",
    "\n",
    "# Iterate the time steps of the recording and check if there is an annotated event at each timestep (Ripple Band)\n",
    "curr_markers_idx = 0\n",
    "for (idx, time_step) in enumerate(x):\n",
    "    # Check if an event occurs at this time step\n",
    "    if curr_markers_idx < len(ripple_selected_ch_markers) and ripple_selected_ch_markers[curr_markers_idx]['position'] <= time_step:\n",
    "        # If the label has an HFO event, mark it as 1 in the target array \n",
    "        # Can use this function since the given labels are already filtered in the desired band\n",
    "        if label_has_hfo_event(ripple_selected_ch_markers[curr_markers_idx]['label']):\n",
    "            ripple_target_np[idx] = 1   # Mark the Labelled event in the target array\n",
    "        \n",
    "        curr_markers_idx += 1    # Move to the next annotated event\n",
    "    \n",
    "    if curr_markers_idx >= len(ripple_selected_ch_markers):\n",
    "        # All the spikes have been added to the input array\n",
    "        break\n",
    "\n",
    "# Iterate the time steps of the recording and check if there is an annotated event at each timestep (Fast Ripple Band)\n",
    "curr_markers_idx = 0\n",
    "for (idx, time_step) in enumerate(x):\n",
    "    # Check if an event occurs at this time step\n",
    "    if curr_markers_idx < len(fr_selected_ch_markers) and fr_selected_ch_markers[curr_markers_idx]['position'] <= time_step:\n",
    "        # If the label has an HFO event, mark it as 1 in the target array \n",
    "        # Can use this function since the given labels are already filtered in the desired band\n",
    "        if label_has_hfo_event(fr_selected_ch_markers[curr_markers_idx]['label']):\n",
    "            fr_target_np[idx] = 1   # Mark the Labelled event in the target array\n",
    "        \n",
    "        curr_markers_idx += 1    # Move to the next annotated event\n",
    "    \n",
    "    if curr_markers_idx >= len(fr_selected_ch_markers):\n",
    "        # All the spikes have been added to the input array\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ripple_target_np Shape: (245760,).\n",
      "Preview: [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "preview_np_array(ripple_target_np, \"ripple_target_np\")\n",
    "print(np.count_nonzero(ripple_target_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr_target_np Shape: (245760,).\n",
      "Preview: [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "preview_np_array(fr_target_np, \"fr_target_np\")\n",
    "print(np.count_nonzero(fr_target_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the target files to numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the target array to a numpy file\n",
    "EXPORT_TARGET = True\n",
    "if EXPORT_TARGET:\n",
    "    ripple_target_file_name = f\"{RESULTS_FOLDER}/ripple_ground_truth.npy\"\n",
    "    # Save the ripple target array to a numpy file\n",
    "    np.save(ripple_target_file_name, ripple_target_np)\n",
    "\n",
    "    # Save the fast ripple target array to a numpy file\n",
    "    fr_target_file_name = f\"{RESULTS_FOLDER}/fr_ground_truth.npy\"\n",
    "    np.save(fr_target_file_name, fr_target_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
