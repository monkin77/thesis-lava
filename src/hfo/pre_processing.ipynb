{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing of the SEEG Signal\n",
    "This notebook presents the pre-processing stages the SEEG signal goes through before being fed to the SNN. The pre-processing stages are as follows:\n",
    "1. **Filtering**: The SEEG signal is bandpass filtered to remove noise and artifacts. The bandpass filter is designed using the Butterworth filter and, since we are working with *iEEG*, the signal is filtered in the ripples and FR bands. The co-occurrence of HFOs in both bands is an optimal prediction of post-surgical seizure freedom by defining an optimal \"HFO area\" or EZ zone.\n",
    "2. **Signal-to-Spike Conversion**: To interface and communicate with the silicon neurons in the SNN, the SEEG signal must be converted to spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Depending on the EEG modality, the signal is filtered in different frequency bands. In this case, since we are handling *iEEG* or *sEEG* data, the signal is filtered in both the ripples (80-250Hz) and FR bands (250-500Hz). The co-occurrence of HFO in these bands represents an optimal prediction of post-surgical seizure freedom by defining an optimal \"HFO area\" or EZ zone.\n",
    "\n",
    "The filter is implemented in different ways depending on the setup it will run on.\n",
    "1. **Neuromorphic Hardware**: The filter is implemented using analog filters. \n",
    "2. **Software Simulation**: *Butterworth filters* are utilized since they are a good approximation of the tuned *Tow-Thomas* architectures implemented in hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency response of the *Butterworth filter* is maximally flat in the passband and rolls of towards 0 in the stopband."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check WD (change if necessary) and file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/monkin/Desktop/feup/thesis/thesis-lava/src/hfo\n"
     ]
    }
   ],
   "source": [
    "# Show current directory\n",
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)\n",
    "\n",
    "# Check if the current WD is the file location\n",
    "if \"/src/hfo\" not in os.getcwd():\n",
    "    # Set working directory to this file location\n",
    "    file_location = f\"{os.getcwd()}/thesis-lava/src/hfo/\"\n",
    "    print(\"File Location: \", file_location)\n",
    "\n",
    "    # Change the current working Directory\n",
    "    os.chdir(file_location)\n",
    "\n",
    "    # New Working Directory\n",
    "    print(\"New Working Directory: \", os.getcwd())\n",
    "\n",
    "PATH_TO_FILE = '' # 'src/hfo/'  # This is needed if the WD is not the same as the file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (245760, 960)\n",
      "First time steps:  [[ 3.2352024e-01 -1.3235390e+00 -5.9668809e-01 ... -1.9608999e+00\n",
      "  -1.9769822e-01 -1.2078454e+00]\n",
      " [-6.9759099e-04 -3.5122361e+00 -4.8766956e-01 ... -5.8757830e+00\n",
      "  -7.4400985e-01 -5.1096064e-01]\n",
      " [ 1.9026639e+00 -5.6726017e+00  9.8274893e-01 ... -6.6182971e+00\n",
      "  -8.3053267e-01 -8.1596655e-01]\n",
      " ...\n",
      " [ 3.2172418e+00 -8.4650068e+00  1.5216088e+00 ... -4.1081657e+00\n",
      "   2.0085973e-01 -4.7539668e+00]\n",
      " [ 1.7725919e+00 -9.4744024e+00  1.6776791e+00 ... -4.1469693e+00\n",
      "   1.6412770e+00 -3.4672713e+00]\n",
      " [ 7.8109097e-01 -1.0500931e+01  2.3717029e+00 ... -5.1762242e+00\n",
      "   1.0715837e+00 -4.4489903e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "seeg_file_name = \"seeg_synthetic_humans.npy\"\n",
    "recorded_data = np.load(f\"{PATH_TO_FILE}data/{seeg_file_name}\")\n",
    "\n",
    "print(\"Data shape: \", recorded_data.shape)\n",
    "print(\"First time steps: \", recorded_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the parent directory to the path to detect the utils module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to the path so it detects the utils module\n",
    "module_path = os.path.abspath(os.path.join('src'))      # Changed this since WD is not the same as the file location\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# ================================================================ #\n",
    "# ============ Butterworth Filter Coefficients =================== #\n",
    "# ================================================================ #\n",
    "def butter_bandpass(lowcut, highcut, sampling_freq, order=5):\n",
    "    \"\"\"\n",
    "    This function is used to generate the coefficients for lowpass, highpass and bandpass\n",
    "    filtering for Butterworth filters.\n",
    "    @lowcut, highcut (int): cutoff frequencies for the bandpass filter\n",
    "    @sampling_freq (float): sampling_frequency frequency of the wideband signal\n",
    "    @order (int): filter order\n",
    "\n",
    "    - return b, a (float): filtering coefficients that will be applied on the wideband signal\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * sampling_freq   # Nyquist frequency\n",
    "    low = lowcut / nyq          # Normalizing the cutoff frequencies\n",
    "    high = highcut / nyq        # Normalizing the cutoff frequencies\n",
    "\n",
    "    return butter(order, [low, high], btype='band')    \n",
    "\n",
    "# ================================================================ #\n",
    "# ====================== Butterworth Filters ===================== #\n",
    "# ================================================================ #\n",
    "def butter_bandpass_filter(data, lowcut, highcut, sampling_freq, order=5):\n",
    "    \"\"\"\n",
    "    This function applies the filtering coefficients calculated above to the wideband signal (original signal).\n",
    "    @data (array): Array with the amplitude values of the wideband signal.\n",
    "    @lowcut, highcut (int): cutoff frequencies for the bandpass filter.\n",
    "    @sampling_freq (float): sampling frequency of the original signal.\n",
    "    @order (int): filter order.\n",
    "\n",
    "    - return (array): Array with the amplitude values of the filtered signal.\n",
    "    \"\"\"\n",
    "    coef_b, coef_a = butter_bandpass(lowcut, highcut, sampling_freq, order)\n",
    "\n",
    "    return lfilter(coef_b, coef_a, data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Global Parameters of the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 2048    # 2048 Hz\n",
    "input_duration = 120 * (10**3)    # 120000 ms or 120 seconds\n",
    "num_samples = recorded_data.shape[0]    # 2048 * 120 = 245760\n",
    "num_channels = recorded_data.shape[1]   # 960\n",
    "\n",
    "x_step = 1/sampling_rate * (10**3)  # 0.48828125 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a window of channels from the SEEG data\n",
    "Let's define the window first.\n",
    "\n",
    "If we want to extract a single channel, set the variable `is_single_channel` to `True` and the variable `min_channel_idx` to the desired channel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_single_channel = False   # Set to True if you want to use only one channel\n",
    "\n",
    "# Define the window of channels to be used\n",
    "min_channel_idx = 90\n",
    "max_channel_idx = min_channel_idx + 30\n",
    "\n",
    "if is_single_channel:\n",
    "    # Set the window to size 1\n",
    "    max_channel_idx = min_channel_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEEG Window Shape: (245760, 30).\n",
      "Preview: [[ 3.2148191e-01  7.6039447e-03  4.7144434e-01  1.6629694e-01\n",
      "   6.4306718e-01 ... -1.0047178e+00 -2.3591769e+00 -9.1859162e-01\n",
      "  -1.1903234e+00 -1.0296663e+00]\n",
      " [-2.0508800e-02 -4.6258485e-01 -7.4022943e-01 -1.8455078e-01\n",
      "   2.1398619e-01 ... -1.3898176e+00 -3.7664881e+00 -1.3889902e+00\n",
      "  -5.1110125e-01 -1.5383426e+00]\n",
      " [-1.2178916e+00 -2.0358562e+00 -1.2876116e+00 -1.3673829e+00\n",
      "   1.2640097e+00 ... -2.6840944e+00 -4.0100474e+00 -1.9828362e+00\n",
      "  -1.4741321e+00 -1.6997232e+00]\n",
      " [-1.0280560e+00 -3.0880692e+00 -1.2848712e+00  2.0071094e-01\n",
      "   2.3219368e+00 ... -1.9042799e+00 -2.8593712e+00 -1.8951950e+00\n",
      "  -2.2079365e+00 -2.1716366e+00]\n",
      " [-1.6502820e+00 -2.6590590e+00 -2.6356335e+00 -1.8437275e-01\n",
      "   4.8591003e+00 ... -7.3706615e-01 -3.4916322e+00 -3.4061065e+00\n",
      "  -1.9112504e+00 -2.1673732e+00]\n",
      " ...\n",
      " [ 5.8455471e+01  5.3846050e+01 -2.0737498e+00 -3.2716221e-01\n",
      "   7.4935384e+00 ...  5.5184326e+01  6.2657150e+01 -5.0081539e+01\n",
      "  -1.8071165e+01 -1.0639250e+01]\n",
      " [ 5.8489109e+01  5.1760201e+01 -4.7800773e-01 -2.2473807e+00\n",
      "   8.8380213e+00 ...  5.4851608e+01  6.1470291e+01 -4.8648796e+01\n",
      "  -1.8093189e+01 -1.1409016e+01]\n",
      " [ 5.8212322e+01  5.2919380e+01  3.4035551e-03 -3.1951135e-01\n",
      "   8.0632792e+00 ...  5.6749435e+01  6.0162395e+01 -4.9130875e+01\n",
      "  -1.8731684e+01 -1.1790145e+01]\n",
      " [ 5.7006664e+01  5.2910263e+01  1.3382965e+00 -9.8228645e-01\n",
      "   8.9594698e+00 ...  5.7541996e+01  5.8091373e+01 -4.8520439e+01\n",
      "  -1.9335537e+01 -1.1269729e+01]\n",
      " [ 5.8805843e+01  5.3754505e+01  6.0538346e-01  7.1650964e-01\n",
      "   7.4029660e+00 ...  5.5387402e+01  5.9551704e+01 -4.7963863e+01\n",
      "  -1.9027611e+01 -1.0325829e+01]]\n"
     ]
    }
   ],
   "source": [
    "from utils.io import preview_np_array\n",
    "seeg_window = recorded_data[:, min_channel_idx:max_channel_idx]\n",
    "\n",
    "preview_np_array(seeg_window, \"SEEG Window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Butterworth filter to each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple Band SEEG Window Shape: (245760, 30).\n",
      "Preview: [[ 1.84829940e-04  4.37174409e-06  2.71047998e-04 ... -5.28126862e-04\n",
      "  -6.84353879e-04 -5.91987150e-04]\n",
      " [ 1.37975809e-03 -2.33040380e-04  1.61508759e-03 ... -4.77473965e-03\n",
      "  -5.44621734e-03 -5.34139889e-03]\n",
      " [ 3.92964380e-03 -3.06118826e-03  2.97532191e-03 ... -2.06351304e-02\n",
      "  -2.05310798e-02 -2.27491617e-02]\n",
      " ...\n",
      " [ 6.57385201e-01  7.72400799e-01 -4.98205341e-01 ... -2.25650820e-01\n",
      "  -1.15243564e+00  1.23691538e+00]\n",
      " [ 5.95894958e-01  5.34762270e-01 -5.39540198e-01 ... -4.98290647e-01\n",
      "  -1.20278059e+00  7.54000855e-01]\n",
      " [ 3.30411778e-01  3.01232878e-01 -5.59614286e-01 ... -8.15564053e-01\n",
      "  -1.14933726e+00  1.73992494e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Apply the Butterworth filter to the window of channels in the Ripple Band\n",
    "ripple_lowcut_freq = 80\n",
    "ripple_highcut_freq = 250\n",
    "\n",
    "ripple_band_seeg_window = [ butter_bandpass_filter(seeg_window[:, i], ripple_lowcut_freq, ripple_highcut_freq, sampling_rate) for i in range(seeg_window.shape[1]) ]\n",
    "ripple_band_seeg_window = np.array(ripple_band_seeg_window).T\n",
    "preview_np_array(ripple_band_seeg_window, \"Ripple Band SEEG Window\", edge_items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR Band SEEG Window Shape: (245760, 30).\n",
      "Preview: [[ 9.55236180e-04  2.25940024e-05  1.40082745e-03 ... -2.72945977e-03\n",
      "  -3.53687062e-03 -3.05950185e-03]\n",
      " [ 3.10524546e-03 -1.29961370e-03  2.44363903e-03 ... -1.31741286e-02\n",
      "  -1.32418198e-02 -1.47118505e-02]\n",
      " [-4.78473281e-03 -1.06279148e-02 -1.25298819e-02 ... -1.68170844e-02\n",
      "  -5.84467919e-03 -1.71137287e-02]\n",
      " ...\n",
      " [ 2.70639699e-01  4.39370956e-01  1.64996622e-01 ... -1.70404540e-02\n",
      "   5.26999132e-01 -4.95964763e-01]\n",
      " [-1.83190240e-01 -4.41412299e-01  4.53359242e-01 ... -5.10423230e-01\n",
      "   1.10863199e-01 -2.75361798e-01]\n",
      " [-3.01458872e-01 -2.90944680e-01  2.09993078e-01 ... -4.26309677e-01\n",
      "  -4.75959832e-01  2.86613031e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Apply the Butterworth filter to the window of channels in the Fast Ripple Band\n",
    "fr_lowcut_freq = 250\n",
    "fr_highcut_freq = 500\n",
    "\n",
    "fr_band_seeg_window = [ butter_bandpass_filter(seeg_window[:, i], fr_lowcut_freq, fr_highcut_freq, sampling_rate) for i in range(seeg_window.shape[1]) ]\n",
    "fr_band_seeg_window = np.array(fr_band_seeg_window).T\n",
    "preview_np_array(fr_band_seeg_window, \"FR Band SEEG Window\", edge_items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Markers (Annotated Events) \n",
    "The markers are stored in a numpy array of shape (num_channels, events):\n",
    "- Each row represents the events of a channel\n",
    "- Each event is composed of the following 3 fields (Label, Position, Shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markers Shape: (960, 42).\n",
      "Preview: [[('Spike+Ripple+Fast-Ripple',   1000.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple',   4537.6 , 0.)\n",
      "  ('Ripple+Fast-Ripple',   7610.84, 0.) ... ('Ripple', 113024.  , 0.)\n",
      "  ('Fast-Ripple', 116549.  , 0.) ('Spike+Ripple', 119000.  , 0.)]\n",
      " [('Spike+Fast-Ripple',   1000.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple',   3849.12, 0.)\n",
      "  ('Ripple+Fast-Ripple',   7010.25, 0.) ...\n",
      "  ('Fast-Ripple', 114176.  , 0.) ('Spike+Fast-Ripple', 116672.  , 0.)\n",
      "  ('Fast-Ripple', 119000.  , 0.)]\n",
      " [('Fast-Ripple',   1000.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple',   4357.42, 0.)\n",
      "  ('Fast-Ripple',   7062.01, 0.) ... ('Spike+Fast-Ripple', 113759.  , 0.)\n",
      "  ('Ripple+Fast-Ripple', 116295.  , 0.) ('Spike', 119000.  , 0.)]\n",
      " ...\n",
      " [('Spike+Fast-Ripple',   1000.  , 0.) ('Spike',   3671.88, 0.)\n",
      "  ('Fast-Ripple',   6912.6 , 0.) ... ('Ripple', 114088.  , 0.)\n",
      "  ('Spike', 116028.  , 0.) ('Spike+Ripple', 119000.  , 0.)]\n",
      " [('Spike+Fast-Ripple',   1000.  , 0.) ('Fast-Ripple',   3782.23, 0.)\n",
      "  ('Ripple+Fast-Ripple',   5976.07, 0.) ... ('Ripple', 113042.  , 0.)\n",
      "  ('Spike', 116026.  , 0.) ('Spike+Fast-Ripple', 119000.  , 0.)]\n",
      " [('Ripple+Fast-Ripple',   1000.  , 0.) ('Spike',   4426.76, 0.)\n",
      "  ('Ripple+Fast-Ripple',   6739.26, 0.) ...\n",
      "  ('Spike+Ripple+Fast-Ripple', 113650.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple', 115972.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple', 119000.  , 0.)]]\n"
     ]
    }
   ],
   "source": [
    "markers_seeg_file_name = \"seeg_synthetic_humans_markers.npy\"\n",
    "markers = np.load(f\"{PATH_TO_FILE}data/{markers_seeg_file_name}\")\n",
    "\n",
    "preview_np_array(markers, \"Markers\", edge_items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the set of channels the markers will be extracted from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels used:  {90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119}\n"
     ]
    }
   ],
   "source": [
    "channels_used = set(range(min_channel_idx, max_channel_idx))\n",
    "print(\"Channels used: \", channels_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the filtered signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Plot for the HFO detection\n",
    "# bokeh docs: https://docs.bokeh.org/en/2.4.1/docs/first_steps/first_steps_1.html\n",
    "\n",
    "from utils.line_plot import create_fig  # Import the function to create the figure\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "# Define the x and y values\n",
    "# Should the first input start at 0 or x_step?\n",
    "# TODO: is it okay to create a range with floats?\n",
    "x = [val for val in np.arange(x_step, input_duration + x_step, x_step)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "# List of tuples containing the y values and the legend label\n",
    "hfo_y_arrays = []\n",
    "\n",
    "if is_single_channel:\n",
    "    # Add the Ripple and FR bands of the single channel\n",
    "    hfo_y_arrays.append((ripple_band_seeg_window[:, 0], f\"Ripple Band Ch. {min_channel_idx}\"))\n",
    "    hfo_y_arrays.append((fr_band_seeg_window[:, 0], f\"Fast Ripple Band Ch. {min_channel_idx}\"))\n",
    "else:\n",
    "    # Add the Ripple and FR bands of each channel in the range defined below\n",
    "    min_hfo_idx = 20\n",
    "    max_hfo_idx = 24\n",
    "    for hfo_idx in range(min_hfo_idx, max_hfo_idx, 1):\n",
    "        hfo_y_arrays.append((ripple_band_seeg_window[:, hfo_idx], f\"Ripple Band Ch. {hfo_idx}\"))\n",
    "        hfo_y_arrays.append((fr_band_seeg_window[:, hfo_idx], f\"Fast Ripple Band Ch. {hfo_idx}\"))\n",
    "\n",
    "\n",
    "# Create the SEEG Voltage plot\n",
    "hfo_plot = create_fig(\n",
    "    title=\"SEEG Voltage dynamics of Filtered Ripple and Fast Ripple Bands\", \n",
    "    x_axis_label='time (ms)', \n",
    "    y_axis_label='Voltage (μV)',\n",
    "    x=x, \n",
    "    y_arrays=hfo_y_arrays, \n",
    "    sizing_mode=\"stretch_both\", \n",
    "    tools=\"pan, box_zoom, wheel_zoom, hover, undo, redo, zoom_in, zoom_out, reset, save\",\n",
    "    tooltips=\"Data point @x: @y\",\n",
    "    legend_location=\"top_right\",\n",
    "    legend_bg_fill_color=\"navy\",\n",
    "    legend_bg_fill_alpha=0.1,\n",
    "    # y_range=Range1d(-0.05, 1.05)\n",
    ")\n",
    "\n",
    "# If there are more than 30 channels, hide the legend\n",
    "if len(hfo_y_arrays) > 30:\n",
    "    # Hide the legend\n",
    "    hfo_plot.legend.visible = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Box Annotations to the plot to identify the marked HFOs (ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import BoxAnnotation\n",
    "# from utils.line_plot import color_map\n",
    "\n",
    "show_markers = False    # Boolean to show the markers\n",
    "\n",
    "color_map = {                  \n",
    "    'Spike': 'red',\n",
    "    'Fast-Ripple': 'blue',\n",
    "    'Ripple': 'green',  \n",
    "    'Spike+Ripple': 'yellow',\n",
    "    'Spike+Fast-Ripple': 'pink',\n",
    "    'Ripple+Fast-Ripple': 'cyan',\n",
    "    'Spike+Ripple+Fast-Ripple': 'black'\n",
    "}\n",
    "\n",
    "confidence_range = 100          # TODO: Check this value. When the duration is missing (0), we consider the 200ms window around the marked position \n",
    "visited_markers = {}    # Avoid inserting multiple boxes for the same marker (only one of each label)\n",
    "use_visited = False     # Boolean controlling if we remove duplicate markers\n",
    "plot_instant = True     # Boolean to plot the markers as instant events or as boxes\n",
    "instant_width = 100 # 20       # Width of the instant event for visualization purposes\n",
    "\n",
    "if show_markers:\n",
    "    for ch_idx in channels_used:\n",
    "        channel_markers = markers[ch_idx]\n",
    "        # print(\"channel_markers\", channel_markers)\n",
    "        for idx2, marker in enumerate(channel_markers):\n",
    "            # print(\"marker:\", marker)\n",
    "            \n",
    "            if use_visited:\n",
    "                # Check if the marker has already been visited and skip it if it has\n",
    "                if marker['position'] in visited_markers:\n",
    "                    visited_labels = visited_markers[marker['position']]    # Get the labels that already have an annotation for this position\n",
    "                    if marker['label'] in visited_labels:\n",
    "                        # print(\"Skipping marker\", marker['position'], marker['label'])\n",
    "                        continue    # Skip this marker\n",
    "                    else:\n",
    "                        visited_labels.append(marker['label'])  # Add the label to the visited labels\n",
    "                else:\n",
    "                    visited_markers[marker['position']] = [marker['label']] # Add the marker to the visited markers\n",
    "\n",
    "            # Add a box annotation for each marker\n",
    "            has_duration = marker['duration'] > 0\n",
    "            \n",
    "            confidence_constant = 0 if plot_instant or has_duration else confidence_range\n",
    "\n",
    "            left = marker['position'] - confidence_constant\n",
    "            right = marker['position'] + confidence_constant + instant_width\n",
    "            box_color = color_map[marker['label']]  # Choose a color according to the label\n",
    "            \n",
    "            # if left < min_t or right > max_t:\n",
    "            #     continue    # Skip this marker\n",
    "            \n",
    "\n",
    "            box = BoxAnnotation(left=left, right=right, fill_color=box_color, fill_alpha=0.35)\n",
    "            # print(\"Added marker for channel: \", ch_idx, \" at position: \", left)\n",
    "            hfo_plot.add_layout(box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bplt\n",
    "\n",
    "showPlot = True\n",
    "if showPlot:\n",
    "    bplt.show(hfo_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the plot to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = False\n",
    "file_name = f\"filtered_seeg_ch{min_hfo_idx}\" if is_single_channel else f\"filtered_seeg_ch{min_hfo_idx}-{max_hfo_idx}\"\n",
    "\n",
    "if export:\n",
    "    file_path = f\"{PATH_TO_FILE}filter_results/synthetic/plots/{file_name}.html\"\n",
    "\n",
    "    # Customize the output file settings\n",
    "    bplt.output_file(filename=file_path, title=\"SEEG Data - Filtered Voltage dynamics across time\")\n",
    "\n",
    "    # Save the plot\n",
    "    bplt.save(hfo_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the filtered signals to a numpy file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the relevant Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Markers Shape: (30, 42).\n",
      "Preview: [[('Spike',   1000.  , 0.) ('Spike+Fast-Ripple',   4218.75, 0.)\n",
      "  ('Ripple+Fast-Ripple',   6966.8 , 0.) ... ('Ripple', 114551.  , 0.)\n",
      "  ('Spike+Ripple', 116517.  , 0.) ('Spike+Ripple', 119000.  , 0.)]\n",
      " [('Spike+Ripple',   1000.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple',   3917.97, 0.)\n",
      "  ('Spike+Fast-Ripple',   6794.92, 0.) ... ('Spike', 113382.  , 0.)\n",
      "  ('Ripple+Fast-Ripple', 116656.  , 0.) ('Spike+Ripple', 119000.  , 0.)]\n",
      " [('Fast-Ripple',   1000.  , 0.) ('Spike',   3655.76, 0.)\n",
      "  ('Spike',   7188.96, 0.) ...\n",
      "  ('Spike+Ripple+Fast-Ripple', 112797.  , 0.)\n",
      "  ('Fast-Ripple', 115363.  , 0.) ('Spike+Fast-Ripple', 119000.  , 0.)]\n",
      " ...\n",
      " [('Ripple+Fast-Ripple',   1000.  , 0.) ('Ripple',   3543.46, 0.)\n",
      "  ('Ripple+Fast-Ripple',   6759.77, 0.) ...\n",
      "  ('Fast-Ripple', 112950.  , 0.) ('Spike+Ripple', 115987.  , 0.)\n",
      "  ('Spike+Ripple', 119000.  , 0.)]\n",
      " [('Spike+Fast-Ripple',   1000.  , 0.) ('Fast-Ripple',   4774.41, 0.)\n",
      "  ('Ripple',   7656.74, 0.) ... ('Spike', 113143.  , 0.)\n",
      "  ('Ripple+Fast-Ripple', 116769.  , 0.) ('Ripple', 119000.  , 0.)]\n",
      " [('Spike+Ripple',   1000.  , 0.) ('Ripple',   4143.07, 0.)\n",
      "  ('Spike+Fast-Ripple',   6804.2 , 0.) ...\n",
      "  ('Ripple+Fast-Ripple', 112313.  , 0.)\n",
      "  ('Spike+Ripple+Fast-Ripple', 115019.  , 0.)\n",
      "  ('Fast-Ripple', 119000.  , 0.)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the relevant markers in a variable\n",
    "relevant_markers = markers[min_channel_idx:max_channel_idx]\n",
    "preview_np_array(relevant_markers, \"Relevant Markers\", edge_items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_FILTERED_SIGNAL = True\n",
    "file_name = f\"filtered_seeg_ch{min_channel_idx}\" if is_single_channel else f\"filtered_seeg_ch{min_channel_idx}-{max_channel_idx-1}\"\n",
    "if EXPORT_FILTERED_SIGNAL:\n",
    "    # Export the filtered signals\n",
    "    np.save(f\"{PATH_TO_FILE}filter_results/synthetic/{file_name}_ripple_band.npy\", ripple_band_seeg_window)\n",
    "    np.save(f\"{PATH_TO_FILE}filter_results/synthetic/{file_name}_fr_band.npy\", fr_band_seeg_window)\n",
    "\n",
    "    # Export the markers\n",
    "    np.save(f\"{PATH_TO_FILE}filter_results/synthetic/{file_name}_markers.npy\", relevant_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "\n",
    "Right now, we have the filtered SEEG signal in both the ripple and FR bands. The next step is to convert the signal to spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal-to-Spike Conversion\n",
    "The signal can be converted to spikes in different ways. First, we will try a method where **two spike trains are generated from the filtered signal**:\n",
    "- **UP Spike Train**: The spikes are generated based on an increase of the signal's amplitude. The spikes are generated when the signal crosses a certain threshold defined by `threshold_up`.\n",
    "- **DOWN Spike Train**: The spikes are generated based on a decrease of the signal's amplitude. The spikes are generated when the signal crosses a certain threshold defined by `threshold_down`.\n",
    "\n",
    "The spike trains are generated by comparing the amount of change in the signal since the last time a spike was generated (UP or DOWN). If the positive/negative amplitude change is greater than the defined threshold, the algorithm stores the current timestep in the respective spike train and takes the new amplitude as the reference for the next comparison.\n",
    "\n",
    "Another important aspect of this algorithm is to model the time that silicon neurons need before they can generate another spike. Both in hardware and software, we call this time `refractory_period`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurable Parameters for the Signal-to-Spike Conversion\n",
    "- `threshold_up`: The threshold for the UP spike train.\n",
    "- `threshold_down`: The threshold for the DOWN spike train.\n",
    "\n",
    "The accuracy of this algorithm is heavily dependent on the choice of these parameters. To find the optimal values, we can perform a ***baseline detection*** to determine the optimal spike generation threshold automatically for the signal conversion.\n",
    "\n",
    "**As a first solution, we set these values manually to have a working prototype. Later, we will find the optimal values and compare the results of both methods.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Move the Signal to Spike Conversion to a separate notebook (loading the seeg data from a .npy file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables of the Signal to Spike Conversion Manually\n",
    "ripple_threshold_up = 5   # Threshold for the UP spike detection (in μV)\n",
    "ripple_threshold_down = -5 # Threshold for the DOWN spike detection (in μV)\n",
    "\n",
    "fr_threshold_up = 3   # Threshold for the UP spike detection (in μV)\n",
    "fr_threshold_down = -3 # Threshold for the DOWN spike detection (in μV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripple UP Spike Train shape:  (3916,) Preview:  [   944.82421875    951.171875      953.125         981.93359375\n",
      "    993.1640625  ... 119509.765625   119510.7421875  119512.6953125\n",
      " 119522.4609375  119534.1796875 ]\n",
      "Ripple DOWN Spike Train shape:  (3917,) Preview:  [   947.265625      948.73046875    956.0546875     979.00390625\n",
      "    989.2578125  ... 119507.32421875 119507.8125     119515.625\n",
      " 119517.08984375 119530.2734375 ]\n"
     ]
    }
   ],
   "source": [
    "from hfo.signal_to_spike.signal_to_spike import signal_to_spike, SignalToSpikeParameters\n",
    "\n",
    "# Convert the filtered ripple signal to spikes\n",
    "ripple_spike_trains = signal_to_spike(\n",
    "    SignalToSpikeParameters(\n",
    "        signal=ripple_band_seeg, times=np.array(x),\n",
    "        threshold_up=ripple_threshold_up, threshold_down=ripple_threshold_down,\n",
    "        # refractory_period=0.002, interpolation_factor=1\n",
    "        )\n",
    ")\n",
    "\n",
    "np.set_printoptions(edgeitems=5)\n",
    "print(\"Ripple UP Spike Train shape: \", ripple_spike_trains.up.shape, \"Preview: \", ripple_spike_trains.up)\n",
    "print(\"Ripple DOWN Spike Train shape: \", ripple_spike_trains.down.shape, \"Preview: \", ripple_spike_trains.down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast Ripple UP Spike Train shape:  (3509,) Preview:  [  1001.953125     1002.44140625   1004.39453125   1004.8828125\n",
      "   1006.8359375  ... 119506.8359375  119507.32421875 119508.7890625\n",
      " 119511.71875    119515.625     ]\n",
      "Fast Ripple DOWN Spike Train shape:  (3452,) Preview:  [  1002.9296875    1003.41796875   1003.90625      1005.37109375\n",
      "   1005.859375   ... 119505.859375   119506.34765625 119509.765625\n",
      " 119514.16015625 119583.984375  ]\n"
     ]
    }
   ],
   "source": [
    "# Convert the filtered FR signal to spikes\n",
    "fr_spike_trains = signal_to_spike(\n",
    "    SignalToSpikeParameters(\n",
    "        signal=fr_band_seeg, times=np.array(x),\n",
    "        threshold_up=fr_threshold_up, threshold_down=fr_threshold_down,\n",
    "        # refractory_period=0.002, interpolation_factor=1\n",
    "        )\n",
    ")\n",
    "\n",
    "np.set_printoptions(edgeitems=5)\n",
    "print(\"Fast Ripple UP Spike Train shape: \", fr_spike_trains.up.shape, \"Preview: \", fr_spike_trains.up)\n",
    "print(\"Fast Ripple DOWN Spike Train shape: \", fr_spike_trains.down.shape, \"Preview: \", fr_spike_trains.down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Spike Trains\n",
    "Let's plot the generated spike trains via a raster plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.raster_plot import create_raster_fig\n",
    "\n",
    "# ------------------------------------------------------------------------------- #\n",
    "# ------- Create the raster plot for the Ripple UP and DOWN spike trains -------- #\n",
    "# ------------------------------------------------------------------------------- #\n",
    "\n",
    "# Create a list containing the x values for the raster plot.\n",
    "ripple_raster_x = np.concatenate((ripple_spike_trains.up, ripple_spike_trains.down), axis=0)\n",
    "\n",
    "# Create a list containing the y values for the raster plot.\n",
    "# The UP spike train will be represented by 1s and the DOWN spike train by 0s\n",
    "ripple_raster_y = [1 for _ in range(len(ripple_spike_trains.up))] + [0 for _ in range(len(ripple_spike_trains.down))]\n",
    "\n",
    "ripple_train_raster = create_raster_fig(\"Ripple UP and DOWN spike events\", \"Time (ms)\", \"Channel\", ripple_raster_x, ripple_raster_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "showRasterPlot = True\n",
    "\n",
    "# Plot the raster plot for the Ripple spike trains\n",
    "if showRasterPlot:\n",
    "    bplt.show(ripple_train_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------- #\n",
    "# ------- Create the raster plot for the Fast Ripple UP and DOWN spike trains -------- #\n",
    "# ------------------------------------------------------------------------------- #\n",
    "\n",
    "# Create a list containing the x values for the raster plot.\n",
    "fr_raster_x = np.concatenate((fr_spike_trains.up, fr_spike_trains.down), axis=0)\n",
    "\n",
    "# Create a list containing the y values for the raster plot.\n",
    "# The UP spike train will be represented by 1s and the DOWN spike train by 0s\n",
    "fr_raster_y = [1 for _ in range(len(fr_spike_trains.up))] + [0 for _ in range(len(fr_spike_trains.down))]\n",
    "\n",
    "fr_train_raster = create_raster_fig(\"Fast Ripple UP and DOWN spike events\", \"Time (ms)\", \"Channel\", fr_raster_x, fr_raster_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raster plot for the Fast Ripple spike trains\n",
    "if showRasterPlot:\n",
    "    bplt.show(fr_train_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Spike Trains to CSV Files for the Lava SNN\n",
    "\n",
    "We have successfully converted the SEEG signal to spikes. The next step is to feed these spikes to the SNN for Ripple and Fast Ripple detection.\n",
    "\n",
    "For this, we will create a file for each type of spike train (UP and DOWN). I'm not sure if we should join the spikes of both bands in a single file or keep them separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file with the spike train data\n",
    "import csv\n",
    "\n",
    "def write_spike_train_to_csv(file_name, spike_train, channel_idx):\n",
    "    \"\"\"\n",
    "    This function writes the spike train to a csv file.\n",
    "    @file_name (str): Name of the file to be created.\n",
    "    @spike_train (np.ndarray): Array with the spike train data.\n",
    "    @channel_idx (int): Index of the channel that generated the spike train. (According to the original data)\n",
    "    \"\"\"\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"time\", \"channel_idx\"])\n",
    "        for spike_time in spike_train:\n",
    "            writer.writerow([spike_time, channel_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE_RIPPLE_CSV_FILES = False\n",
    "WRITE_FR_CSV_FILES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_RIPPLE_CSV_FILES:\n",
    "    # Create the csv file for the Ripple UP spike train\n",
    "    ripple_up_file_name = f\"{PATH_TO_FILE}snn/data/ripple_up_spike_train_5.csv\"\n",
    "    write_spike_train_to_csv(ripple_up_file_name, ripple_spike_trains.up, selected_ch_idx)\n",
    "\n",
    "    # Create the csv file for the Ripple DOWN spike train\n",
    "    ripple_down_file_name = f\"{PATH_TO_FILE}snn/data/ripple_down_spike_train_-5.csv\"\n",
    "    write_spike_train_to_csv(ripple_down_file_name, ripple_spike_trains.down, selected_ch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_FR_CSV_FILES:\n",
    "    # Create the csv file for the Fast Ripple UP spike train\n",
    "    fr_up_file_name = f\"{PATH_TO_FILE}snn/data/fr_up_spike_train_3.csv\"\n",
    "    write_spike_train_to_csv(fr_up_file_name, fr_spike_trains.up, selected_ch_idx)\n",
    "\n",
    "    # Create the csv file for the Fast Ripple DOWN spike train\n",
    "    fr_down_file_name = f\"{PATH_TO_FILE}snn/data/fr_down_spike_train_-3.csv\"\n",
    "    write_spike_train_to_csv(fr_down_file_name, fr_spike_trains.down, selected_ch_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the input files for the SNN\n",
    "\n",
    "### Is the SNN going to detect the HFO events in windows? Or do we take it as a continous input?\n",
    "**If so**: The SNN is going to detect HFO events in windows. Therefore, the input to the network must be organized in windows of a certain size. The size of the window is a hyperparameter that can be tuned to improve the performance of the network.\n",
    "\n",
    "I think windowing makes more sense when we are learning with an ANN. Since we want real-time detection, feeding a continous input makes more sense.\n",
    "\n",
    "### Let's assume we do NOT need to window the input\n",
    "In this case, our input will simply be a continous stream of spikes. We can feed the spikes to the SNN in real-time. At each timestep, the SNN will receive 2 binary inputs (UP and DOWN spikes) indicating the presence of a spike in the respective spike train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snn_input:  (245760, 2) Preview: [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " ...\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array that will store the input (2D)\n",
    "snn_input = np.zeros((num_samples, 2))  # 2 columns: UP and DOWN spike trains\n",
    "\n",
    "# ---------------------------------------------------------------------------------- #\n",
    "# -------- Select the Spike Trains to be used as input for the SNN ----------------- #\n",
    "# ---------------------------------------------------------------------------------- #\n",
    "selected_up_spikes = ripple_spike_trains.up\n",
    "selected_down_spikes = ripple_spike_trains.down\n",
    "\n",
    "# Iterate the time steps of the recording and check if there are spikes in the selected spike trains at each timestep\n",
    "curr_up_idx = 0\n",
    "curr_down_idx = 0\n",
    "for (idx, time_step) in enumerate(x):\n",
    "    # Check if an UP spike occurs at this time step\n",
    "    if curr_up_idx < len(selected_up_spikes) and selected_up_spikes[curr_up_idx] <= time_step:\n",
    "        snn_input[idx][0] = 1   # Mark the UP spike in the input array\n",
    "        curr_up_idx += 1    # Move to the next spike in the UP spike train\n",
    "    # Check if a DOWN spike occurs at this time step\n",
    "    elif curr_down_idx < len(selected_down_spikes) and selected_down_spikes[curr_down_idx] <= time_step:\n",
    "        snn_input[idx][1] = 1   # Mark the DOWN spike in the input array\n",
    "        curr_down_idx += 1  # Move to the next spike in the DOWN spike train\n",
    "    \n",
    "    if curr_up_idx >= len(selected_up_spikes) and curr_down_idx >= len(selected_down_spikes):\n",
    "        # All the spikes have been added to the input array\n",
    "        break\n",
    "\n",
    "np.set_printoptions(edgeitems=5)\n",
    "print(\"snn_input: \", snn_input.shape, \"Preview:\", snn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the input array to a numpy file\n",
    "EXPORT_INPUT = False\n",
    "if EXPORT_INPUT:\n",
    "    input_file_name = f\"{PATH_TO_FILE}snn/data/ripple_train_5_-5/snn_input_ripple_5_-5.npy\"\n",
    "    np.save(input_file_name, snn_input)\n",
    "\n",
    "    # Export to CSV for visualization purposes\n",
    "    with open(f\"{PATH_TO_FILE}snn/data/ripple_train_5_-5/snn_input_ripple_5_-5.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"time\", \"up_spike\", \"down_spike\"])\n",
    "        for (idx, time_step) in enumerate(x):\n",
    "            writer.writerow([time_step, snn_input[idx][0], snn_input[idx][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Ground Truth File for the SNN (Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the markers from the selected channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Channel Markers Shape: (42,).\n",
      "Preview: [('Spike+Fast-Ripple',   1000.  , 0.) ('Spike+Ripple',   4139.16, 0.)\n",
      " ('Spike+Ripple',   7255.86, 0.) ('Spike',  10473.6 , 0.)\n",
      " ('Spike+Ripple+Fast-Ripple',  13362.8 , 0.) ...\n",
      " ('Spike+Ripple', 108516.  , 0.) ('Ripple', 111657.  , 0.)\n",
      " ('Ripple+Fast-Ripple', 114574.  , 0.) ('Spike', 116793.  , 0.)\n",
      " ('Spike+Ripple', 119000.  , 0.)]\n"
     ]
    }
   ],
   "source": [
    "from utils.io import preview_np_array\n",
    "\n",
    "# The target output for the SNN must have the same length as the input.\n",
    "target_np = np.zeros((num_samples))  # 1 column: 0/1 for the output classes (No Event, Ripple/Fast Ripple or both)\n",
    "# TODO: Could have more than 2 classes to differentiate the labels\n",
    "\n",
    "# Get the markers for the selected channel\n",
    "# Each marker has the following keys:   position, label, and duration\n",
    "selected_ch_markers = markers[selected_ch_idx]\n",
    "preview_np_array(selected_ch_markers, \"Selected Channel Markers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to a CSV File for the Lava SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the target array to a numpy file\n",
    "EXPORT_TARGET_1 = False\n",
    "\n",
    "if EXPORT_TARGET_1:\n",
    "    target_file_name = f\"{PATH_TO_FILE}snn/ground_truth/instants_ch-{selected_ch_idx}.npy\"\n",
    "    np.save(target_file_name, target_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to the format that the learnable SNN (Slayer) can read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the target numpy array with 1s where the HFOs are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.input import label_has_hfo_event\n",
    "\n",
    "# Iterate the time steps of the recording and check if there is an annotated event at each timestep\n",
    "curr_markers_idx = 0\n",
    "for (idx, time_step) in enumerate(x):\n",
    "    # Check if an event occurs at this time step\n",
    "    if curr_markers_idx < len(selected_ch_markers) and selected_ch_markers[curr_markers_idx]['position'] <= time_step:\n",
    "        # If the label has an HFO event, mark it as 1 in the target array\n",
    "        if label_has_hfo_event(selected_ch_markers[curr_markers_idx]['label']):\n",
    "            target_np[idx] = 1   # Mark the Labelled event in the target array\n",
    "        \n",
    "        curr_markers_idx += 1    # Move to the next annotated event\n",
    "    \n",
    "    if curr_markers_idx >= len(selected_ch_markers):\n",
    "        # All the spikes have been added to the input array\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_np Shape: (245760,).\n",
      "Preview: [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "preview_np_array(target_np, \"target_np\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the target file to a numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the target array to a numpy file\n",
    "EXPORT_TARGET = False\n",
    "if EXPORT_TARGET:\n",
    "    target_file_name = f\"{PATH_TO_FILE}snn/ground_truth/ch-{selected_ch_idx}.npy\"\n",
    "    np.save(target_file_name, target_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
