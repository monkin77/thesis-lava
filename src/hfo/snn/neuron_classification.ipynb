{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of the Feature Neurons from the SNN\n",
    "This notebook performs the classification of the feature neurons from the SNN according to certain criteria. In the future, it would be interesting to implement a 3rd layer in the SNN to classify the feature neurons automatically. For now, this manual classification will classify each neuron as one of the following:\n",
    "- **Silent Neuron**: Neuron that does not fire at all.\n",
    "- **Noisy Neuron**: Neuron that fires randomly or without a relevant pattern.\n",
    "- **Ripple Neuron**: Neuron that fires in the presence of a ripple.\n",
    "- **Fast Ripple Neuron**: Neuron that fires in the presence of a fast ripple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check WD (change if necessary) and file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/monkin/Desktop/feup/thesis/thesis-lava/src/hfo/snn\n"
     ]
    }
   ],
   "source": [
    "# Show current directory\n",
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)\n",
    "\n",
    "# Check if the current WD is the file location\n",
    "if \"/src/hfo/snn\" not in os.getcwd():\n",
    "    # Set working directory to this file location\n",
    "    file_location = f\"{os.getcwd()}/thesis-lava/src/hfo/snn\"\n",
    "    print(\"File Location: \", file_location)\n",
    "\n",
    "    # Change the current working Directory\n",
    "    os.chdir(file_location)\n",
    "\n",
    "    # New Working Directory\n",
    "    print(\"New Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Voltage and Current Dynamics during the SNN run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_dynamics Shape: (6000, 256).\n",
      "Preview: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 3.71407560e-07 -7.73648026e-09 -2.78799703e-07 ... -6.19488685e-10\n",
      "  -2.18761259e-07 -1.63569169e-08]\n",
      " [ 3.45409031e-07 -7.19492664e-09 -2.59283724e-07 ... -5.76124477e-10\n",
      "  -2.03447971e-07 -1.52119327e-08]\n",
      " [ 3.21230399e-07 -6.69128178e-09 -2.41133863e-07 ... -5.35795763e-10\n",
      "  -1.89206613e-07 -1.41470974e-08]]\n",
      "u_dynamics Shape: (6000, 256).\n",
      "Preview: [[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [1.37727957e-029 1.99570606e-031 6.29823267e-092 ... 4.76762751e-063\n",
      "  8.82690148e-150 0.00000000e+000]\n",
      " [9.83105597e-030 1.39398368e-031 2.14687255e-092 ... 2.28950331e-063\n",
      "  1.51419899e-150 0.00000000e+000]\n",
      " [7.01743230e-030 9.73685723e-032 7.31802392e-093 ... 1.09946202e-063\n",
      "  2.59751238e-151 0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.io import preview_np_array\n",
    "from utils.input import MarkerType, band_to_file_name\n",
    "\n",
    "# Declare if using ripples, fast ripples, or both\n",
    "chosen_band = MarkerType.FAST_RIPPLE     # RIPPLE, FAST_RIPPLE, or BOTH\n",
    "band_file_name = band_to_file_name(chosen_band)\n",
    "\n",
    "INPUT_PATH = f\"./results/custom_subset_90-119_segment500_200\"\n",
    "TIME_SUFFIX = \"time900-6000-1\"\n",
    "\n",
    "# Load the voltage and current data from the numpy files\n",
    "voltage_file_name = f\"{INPUT_PATH}/{band_file_name}_v_dynamics_0.07dv_5ch_{TIME_SUFFIX}.npy\"\n",
    "current_file_name = f\"{INPUT_PATH}/{band_file_name}_u_dynamics_0.07dv_5ch_{TIME_SUFFIX}.npy\"\n",
    "\n",
    "v_dynamics = np.load(voltage_file_name)\n",
    "u_dynamics = np.load(current_file_name)\n",
    "\n",
    "preview_np_array(v_dynamics, \"v_dynamics\", edge_items=3)\n",
    "preview_np_array(u_dynamics, \"u_dynamics\", edge_items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the SNN Configuration and extract the fields\n",
    "The SNN configuration contains:\n",
    "- Numpy array with the ground_truth for each timestep\n",
    "- Initial Time Offset\n",
    "- Virtual Time Step Interval\n",
    "- Number of Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth Shape: (199,).\n",
      "Preview: [('Fast-Ripple',   1000.  , 0.)\n",
      " ('Spike+Ripple+Fast-Ripple',   3206.54, 0.)\n",
      " ('Fast-Ripple',   3770.02, 0.) ... ('Fast-Ripple', 116096.  , 0.)\n",
      " ('Ripple+Fast-Ripple', 116769.  , 0.) ('Fast-Ripple', 119000.  , 0.)]\n",
      "init_offset:  900\n",
      "virtual_time_step_interval:  1\n",
      "num_steps:  6000\n"
     ]
    }
   ],
   "source": [
    "from utils.snn import SNNSimConfig\n",
    "\n",
    "# Load the SNN Config data\n",
    "snn_config_file_name = f\"{INPUT_PATH}/{band_file_name}_snn_config_{TIME_SUFFIX}.npy\"\n",
    "\n",
    "# Load the SNNConfig data as an element of the class SNNConfig\n",
    "snn_config: SNNSimConfig = np.load(snn_config_file_name, allow_pickle=True).item()\n",
    "\n",
    "# Extract the data fields from the SNNConfig object\n",
    "ground_truth: np.ndarray = snn_config.ground_truth\n",
    "init_offset = snn_config.init_offset\n",
    "virtual_time_step_interval = snn_config.virtual_time_step_interval\n",
    "num_steps = snn_config.num_steps\n",
    "\n",
    "preview_np_array(ground_truth, \"ground_truth\", edge_items=3)\n",
    "np.count_nonzero(ground_truth)\n",
    "\n",
    "print(\"init_offset: \", init_offset)\n",
    "print(\"virtual_time_step_interval: \", virtual_time_step_interval)\n",
    "print(\"num_steps: \", num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the timesteps where the network spiked\n",
    "Let's find the timesteps where the network spiked and create a `dictionary` mapping each feature neuron to the timesteps where it spiked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron_spike_times:  {0: [1007, 1010, 3209, 3226, 3229, 3777, 3780, 4142, 4145, 4148, 4781, 4799, 6286, 6290, 6682, 6694], 43: [1008, 4143], 1: [1009, 1017, 3228, 3781, 4146, 4149, 4788, 6291, 6685, 6695], 44: [1011], 88: [1014], 126: [1018], 13: [3222], 17: [3225], 83: [3227], 98: [3230], 50: [3232, 3785], 108: [3233], 18: [3770, 4135, 4775, 6678], 22: [3773], 8: [3776, 4141, 6679, 6692], 10: [3779, 4144], 14: [3784, 4147], 209: [3795], 29: [4138], 247: [4151], 21: [4152], 207: [4153], 201: [4777], 5: [4778, 4792], 107: [4789], 11: [6288], 2: [6289], 239: [6696]}\n"
     ]
    }
   ],
   "source": [
    "from utils.data_analysis import find_spike_times\n",
    "\n",
    "# Create a map storing the spike times for each feature neuron\n",
    "neuron_spike_times = {}\n",
    "\n",
    "# Call the find_spike_times util function that detects the spikes in a voltage array\n",
    "spike_times_lif1 = find_spike_times(v_dynamics, u_dynamics)\n",
    "\n",
    "total_spikes_count = 0\n",
    "for (spike_time, neuron_idx) in spike_times_lif1:\n",
    "    # Calculate the spike time in ms\n",
    "    real_spike_time = init_offset + spike_time * virtual_time_step_interval\n",
    "\n",
    "    # If the neuron index is not in the map (first time the feature neuron spikes), add it\n",
    "    if neuron_idx not in neuron_spike_times:\n",
    "        neuron_spike_times[neuron_idx] = [real_spike_time]\n",
    "    # Otherwise, append the spike time to the list of spike times for that neuron\n",
    "    else:\n",
    "        neuron_spike_times[neuron_idx].append(real_spike_time)\n",
    "    total_spikes_count += 1\n",
    "\n",
    "    # print(f\"Spike time: {real_spike_time} (iter. {spike_time}) at neuron: {neuron_idx}\")\n",
    "\n",
    "# Print the spike times for each feature neuron\n",
    "print(\"neuron_spike_times: \", neuron_spike_times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Time Window after the event insertion to consider as part of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time window after an HFO insertion to consider as part of the event\n",
    "ripple_confidence_window = 120  # Let's give a 120ms window after the Ripple to consider as part of the event\n",
    "fr_confidence_window = 60  # Let's give a 60ms window after the Fast Ripple to consider as part of the event    (TODO: Could be changed)\n",
    "both_confidence_window = 120  # Let's give a 120ms window after the HFO event (Ripple or Fast Ripple) insertion to consider as part of the event\n",
    "\n",
    "confidence_window = ripple_confidence_window\n",
    "if chosen_band == MarkerType.FAST_RIPPLE:\n",
    "    confidence_window = fr_confidence_window\n",
    "elif chosen_band == MarkerType.BOTH:\n",
    "    confidence_window = both_confidence_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the spikes that occur at a distance less than the confidence window\n",
    "In order to calculate the efficiency of the feature neurons, we need to merge the spikes that occur at a distance less than the time window. Otherwise, we would be counting the same event multiple times, which would lead to an overestimation of the efficiency.\n",
    "\n",
    "This is **probably** safe, since each annotated event occurs at a distance greater than the considered time window, usually at least 1 order of magnitude greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged neuron_spike_times:  {0: [1007, 3209, 3777, 4142, 4781, 6286, 6682], 43: [1008, 4143], 1: [1009, 3228, 3781, 4146, 4788, 6291, 6685], 44: [1011], 88: [1014], 126: [1018], 13: [3222], 17: [3225], 83: [3227], 98: [3230], 50: [3232, 3785], 108: [3233], 18: [3770, 4135, 4775, 6678], 22: [3773], 8: [3776, 4141, 6679], 10: [3779, 4144], 14: [3784, 4147], 209: [3795], 29: [4138], 247: [4151], 21: [4152], 207: [4153], 201: [4777], 5: [4778], 107: [4789], 11: [6288], 2: [6289], 239: [6696]}\n",
      "Merged a total of 14 spikes out of 63 spikes\n"
     ]
    }
   ],
   "source": [
    "# Merge the spikes that occur at a distance less than the confidence window\n",
    "merged_spikes_counter = 0\n",
    "for neuron_key in neuron_spike_times.keys():\n",
    "    spike_times = neuron_spike_times[neuron_key]\n",
    "\n",
    "    # Array with the merged spike times\n",
    "    merged_spike_times = [spike_times[0]]\n",
    "\n",
    "    curr_idx = 1\n",
    "    comparison_idx = 0\n",
    "    while curr_idx < len(spike_times):\n",
    "        spike_time = spike_times[curr_idx]\n",
    "        prev_spike_time = spike_times[comparison_idx]\n",
    "\n",
    "        if spike_time - prev_spike_time < confidence_window:\n",
    "            # This spike is part of the same event\n",
    "            curr_idx += 1\n",
    "            merged_spikes_counter += 1\n",
    "            continue\n",
    "        else:\n",
    "            # This spike is part of a new event\n",
    "            merged_spike_times.append(spike_time)\n",
    "            comparison_idx = curr_idx   # Update the comparison index to the new spike time\n",
    "            curr_idx += 1\n",
    "\n",
    "    # Update the neuron_spike_times map with the merged spike times\n",
    "    neuron_spike_times[neuron_key] = merged_spike_times\n",
    "\n",
    "# Print the spike times for each feature neuron\n",
    "print(\"Merged neuron_spike_times: \", neuron_spike_times)\n",
    "\n",
    "print(f\"Merged a total of {merged_spikes_counter} spikes out of {total_spikes_count} spikes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the SNN running time and classify the feature neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy array with the classification of each feature neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_neuron_class Shape: (256,).\n",
      "Preview: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from utils.snn import NeuronClass\n",
    "\n",
    "# Create numpy array containing the class of each feature neuron\n",
    "feature_neuron_class = np.full(shape=(v_dynamics.shape[1]), fill_value=NeuronClass.SILENT)\n",
    "preview_np_array(feature_neuron_class, \"feature_neuron_class\", edge_items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep track of the relevant events each feature neuron detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_neuron_spike_times:  {0: [], 43: [], 1: [], 44: [], 88: [], 126: [], 13: [], 17: [], 83: [], 98: [], 50: [], 108: [], 18: [], 22: [], 8: [], 10: [], 14: [], 209: [], 29: [], 247: [], 21: [], 207: [], 201: [], 5: [], 107: [], 11: [], 2: [], 239: []}\n"
     ]
    }
   ],
   "source": [
    "# Define a map to keep track of the number of relevant events each feature neuron detected\n",
    "relevant_neuron_spike_times = {}\n",
    "\n",
    "# Create an empty list for each feature neuron with spikes\n",
    "for neuron_idx in neuron_spike_times.keys():\n",
    "    relevant_neuron_spike_times[neuron_idx] = []\n",
    "\n",
    "print(\"relevant_neuron_spike_times: \", relevant_neuron_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method that searches for a relevant event in the ground_truth np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truth_timestamps Shape: (199,).\n",
      "Preview: [  1000.     3206.54   3770.02 ... 116096.   116769.   119000.  ]\n"
     ]
    }
   ],
   "source": [
    "# Declare a sorted np.array of the ground truth events by timestamp\n",
    "ground_truth_timestamps = np.array([ann_event[1] for ann_event in ground_truth])\n",
    "\n",
    "preview_np_array(ground_truth_timestamps, \"ground_truth_timestamps\", edge_items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_relevant_event(spike_time, confidence_window):\n",
    "    \"\"\"\n",
    "    Searches for a relevant event in the ground truth array given a timestamp.\n",
    "    The annotated event must be located before the spike time, since the annotation\n",
    "    corresponds to the insertion of the event.\n",
    "    Thus, the Event must be in the window [spike_time - confidence_window, spike_time]\n",
    "    \"\"\"\n",
    "    for event_time in ground_truth_timestamps:\n",
    "        if spike_time - confidence_window <= event_time <= spike_time:\n",
    "            return True\n",
    "        \n",
    "        if event_time > spike_time:\n",
    "            # Since the events are sorted, if the event_time is greater than the spike_time, we can stop looking\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_neuron_spike_times:  {0: [1007, 3209, 3777, 4142, 4781, 6286], 43: [1008, 4143], 1: [1009, 3228, 3781, 4146, 4788, 6291], 44: [1011], 88: [1014], 126: [1018], 13: [3222], 17: [3225], 83: [3227], 98: [3230], 50: [3232, 3785], 108: [3233], 18: [4135, 4775], 22: [3773], 8: [3776, 4141], 10: [3779, 4144], 14: [3784, 4147], 209: [3795], 29: [4138], 247: [4151], 21: [4152], 207: [4153], 201: [4777], 5: [4778], 107: [4789], 11: [6288], 2: [6289], 239: [6696]}\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the feature neurons that spiked\n",
    "for neuron_idx in neuron_spike_times.keys():\n",
    "    curr_spike_times = neuron_spike_times[neuron_idx]\n",
    "    \n",
    "    # For each Spike\n",
    "    for curr_spike_time in curr_spike_times:\n",
    "        # Since the SNN will spike after the insertion of the event, we need to consider the confidence window before the SNN spike.\n",
    "        # The Annotated event is located at the insertion time (before)\n",
    "\n",
    "        # Check if the ground truth contains at least 1 annotated event within the confidence window\n",
    "        if has_relevant_event(curr_spike_time, confidence_window):\n",
    "            # Add the event to the relevant neuron spike times\n",
    "            relevant_neuron_spike_times[neuron_idx].append(curr_spike_time)\n",
    "\n",
    "print(\"relevant_neuron_spike_times: \", relevant_neuron_spike_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics regarding the spiking neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array containing the relevant spike ratio for each feature neuron \n",
    "# in the order of their keys\n",
    "relevant_spike_ratios = []\n",
    "for neuron_idx in neuron_spike_times.keys():\n",
    "    # Get all the spikes of the current neuron\n",
    "    curr_spike_times = neuron_spike_times[neuron_idx]\n",
    "    # Get the relevant spikes of the current neuron\n",
    "    relevant_spike_times = relevant_neuron_spike_times[neuron_idx]\n",
    "\n",
    "    # Calculate the ratio of relevant spikes\n",
    "    relevant_spike_ratio = (len(relevant_spike_times) / len(curr_spike_times)) * 100 if len(curr_spike_times) > 0 else 0.0\n",
    "    relevant_spike_ratios.append(relevant_spike_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron 0: \n",
      "Spikes: [1007, 3209, 3777, 4142, 4781, 6286, 6682]\n",
      "Relevant Spikes: [1007, 3209, 3777, 4142, 4781, 6286]\n",
      "Relevant Spikes Ratio: 85.71428571428571%\n",
      "================================================================\n",
      "\n",
      "Neuron 43: \n",
      "Spikes: [1008, 4143]\n",
      "Relevant Spikes: [1008, 4143]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 1: \n",
      "Spikes: [1009, 3228, 3781, 4146, 4788, 6291, 6685]\n",
      "Relevant Spikes: [1009, 3228, 3781, 4146, 4788, 6291]\n",
      "Relevant Spikes Ratio: 85.71428571428571%\n",
      "================================================================\n",
      "\n",
      "Neuron 44: \n",
      "Spikes: [1011]\n",
      "Relevant Spikes: [1011]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 88: \n",
      "Spikes: [1014]\n",
      "Relevant Spikes: [1014]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 126: \n",
      "Spikes: [1018]\n",
      "Relevant Spikes: [1018]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 13: \n",
      "Spikes: [3222]\n",
      "Relevant Spikes: [3222]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 17: \n",
      "Spikes: [3225]\n",
      "Relevant Spikes: [3225]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 83: \n",
      "Spikes: [3227]\n",
      "Relevant Spikes: [3227]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 98: \n",
      "Spikes: [3230]\n",
      "Relevant Spikes: [3230]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 50: \n",
      "Spikes: [3232, 3785]\n",
      "Relevant Spikes: [3232, 3785]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 108: \n",
      "Spikes: [3233]\n",
      "Relevant Spikes: [3233]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 18: \n",
      "Spikes: [3770, 4135, 4775, 6678]\n",
      "Relevant Spikes: [4135, 4775]\n",
      "Relevant Spikes Ratio: 50.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 22: \n",
      "Spikes: [3773]\n",
      "Relevant Spikes: [3773]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 8: \n",
      "Spikes: [3776, 4141, 6679]\n",
      "Relevant Spikes: [3776, 4141]\n",
      "Relevant Spikes Ratio: 66.66666666666666%\n",
      "================================================================\n",
      "\n",
      "Neuron 10: \n",
      "Spikes: [3779, 4144]\n",
      "Relevant Spikes: [3779, 4144]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 14: \n",
      "Spikes: [3784, 4147]\n",
      "Relevant Spikes: [3784, 4147]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 209: \n",
      "Spikes: [3795]\n",
      "Relevant Spikes: [3795]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 29: \n",
      "Spikes: [4138]\n",
      "Relevant Spikes: [4138]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 247: \n",
      "Spikes: [4151]\n",
      "Relevant Spikes: [4151]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 21: \n",
      "Spikes: [4152]\n",
      "Relevant Spikes: [4152]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 207: \n",
      "Spikes: [4153]\n",
      "Relevant Spikes: [4153]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 201: \n",
      "Spikes: [4777]\n",
      "Relevant Spikes: [4777]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 5: \n",
      "Spikes: [4778]\n",
      "Relevant Spikes: [4778]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 107: \n",
      "Spikes: [4789]\n",
      "Relevant Spikes: [4789]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 11: \n",
      "Spikes: [6288]\n",
      "Relevant Spikes: [6288]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 2: \n",
      "Spikes: [6289]\n",
      "Relevant Spikes: [6289]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n",
      "Neuron 239: \n",
      "Spikes: [6696]\n",
      "Relevant Spikes: [6696]\n",
      "Relevant Spikes Ratio: 100.0%\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PLOT_RELEVANCY_STATS = True\n",
    "\n",
    "if PLOT_RELEVANCY_STATS:\n",
    "    # Iterate over the feature neurons that spiked\n",
    "    for iter_idx, neuron_idx in enumerate(neuron_spike_times.keys()):\n",
    "        # Get all the spikes of the current neuron\n",
    "        curr_spike_times = neuron_spike_times[neuron_idx]\n",
    "\n",
    "        # Get the relevant spikes of the current neuron\n",
    "        relevant_spike_times = relevant_neuron_spike_times[neuron_idx]\n",
    "\n",
    "        print(f\"Neuron {neuron_idx}: \")\n",
    "        print(f\"Spikes: {curr_spike_times}\")\n",
    "        print(f\"Relevant Spikes: {relevant_spike_times}\")\n",
    "        print(f\"Relevant Spikes Ratio: {relevant_spike_ratios[iter_idx]}%\")\n",
    "        print(\"================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Relevant Spike Ratio of the Feature Neurons that Spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot containing the % of relevant spikes for each feature neuron \n",
    "from utils.bar_plot import create_bar_fig  # Import the function to create the figure\n",
    "\n",
    "# Define the x and y values\n",
    "neuron_label = [f\"Neu. {neuron_idx}\" for neuron_idx in neuron_spike_times.keys()]\n",
    "\n",
    "# sorting the bars means sorting the range factors\n",
    "neurons_descending_rel_ratio = sorted(neuron_label, key=lambda x: relevant_spike_ratios[neuron_label.index(x)], reverse=True)\n",
    "\n",
    "# Create the LIF1 Voltage\n",
    "feat_neurons_relevancy_plot = create_bar_fig(\n",
    "    title=\"Feature Neurons Relevant Spikes Ratio\", \n",
    "    x_axis_label='Feature Neuron Index', \n",
    "    y_axis_label='Relevant Spike Ratio (%)',\n",
    "    x=neuron_label,\n",
    "    y=relevant_spike_ratios,\n",
    "    x_range=neurons_descending_rel_ratio,\n",
    "    sizing_mode=\"stretch_width\",\n",
    "    bar_width=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bplt\n",
    "\n",
    "showPlot = True\n",
    "if showPlot:\n",
    "    # Show the plot\n",
    "    bplt.show(feat_neurons_relevancy_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_RELEVANCY_PLOT = False\n",
    "OUTPUT_FOLDER = \"./neuron_classification/custom_subset_90-119_segment500_200\"\n",
    "\n",
    "if EXPORT_RELEVANCY_PLOT:\n",
    "    file_path = f\"{OUTPUT_FOLDER}/{band_file_name}_relevancy_barplot_0.07dv_time{init_offset}-{num_steps}-{virtual_time_step_interval}.html\"\n",
    "\n",
    "    # Customize the output file settings\n",
    "    bplt.output_file(filename=file_path, title=\"Feature Neurons Relevancy (%) Bar Plot\")\n",
    "\n",
    "    # Save the plot\n",
    "    bplt.save(feat_neurons_relevancy_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the Feature Neurons according to their Spiking Activity\n",
    "In this step, we will update the `feature_neuron_class` array with the classification of the `Noisy Neurons`, `Ripple Neurons` and `Fast Ripple Neurons`.\n",
    "\n",
    "We set a **threshold of 0.9** for the `Relevant Spike Ratio` to classify a neuron as a `Ripple` or `Fast Ripple` Neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.snn import marker_type_to_neuron_class\n",
    "\n",
    "relevant_ratio_threshold = 90.0\n",
    "\n",
    "# Iterate over the feature neurons that spiked\n",
    "for iter_idx, neuron_idx in enumerate(neuron_spike_times.keys()):\n",
    "    # Get all the spikes of the current neuron\n",
    "    curr_spike_times = neuron_spike_times[neuron_idx]\n",
    "    # Get the relevant spikes of the current neuron\n",
    "    relevant_spike_times = relevant_neuron_spike_times[neuron_idx]\n",
    "    # Get the relevant spikes ratio of the current neuron\n",
    "    relevant_spike_ratio = relevant_spike_ratios[iter_idx]\n",
    "\n",
    "    if relevant_spike_ratio >= relevant_ratio_threshold:\n",
    "        # Classify the Neuron as a RIPPLE/FAST RIPPLE/BOTH detector based on the band we are analyzing\n",
    "        feature_neuron_class[neuron_idx] = marker_type_to_neuron_class(chosen_band)\n",
    "    else:\n",
    "        # Classify the Neuron as Noisy\n",
    "        feature_neuron_class[neuron_idx] = NeuronClass.NOISY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the classification of the Feature Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_neuron_class Shape: (256,).\n",
      "Preview: [1 1 3 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "preview_np_array(feature_neuron_class, \"feature_neuron_class\", edge_items=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
