{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN that detects High Frequency Oscillations (HFOs) with constant parameters\n",
    "This notebook is a simple example of how to use a Spiking Neural Network (SNN) to detect HFOs\n",
    "\n",
    "### What is an HFO?\n",
    "High Frequency Oscillations (HFOs) are a type of brain activity that occurs in the range of 80-500 Hz. They are believed to be related to the generation of seizures in patients with epilepsy. The detection of HFOs is an important task in the diagnosis and treatment of epilepsy. \n",
    "\n",
    "In terms of electrophysiology, HFOs are characterized by their high frequency and short duration, often lasting only a few milliseconds. The wave of a typical HFO consists of at least 4 UP and DOWN waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mLIF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Leaky-Integrate-and-Fire (LIF) neural Process.\n",
      "\n",
      "LIF dynamics abstracts to:\n",
      "u[t] = u[t-1] * (1-du) + a_in         # neuron current\n",
      "v[t] = v[t-1] * (1-dv) + u[t] + bias  # neuron voltage\n",
      "s_out = v[t] > vth                    # spike if threshold is exceeded\n",
      "v[t] = 0                              # reset at spike\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "shape : tuple(int)\n",
      "    Number and topology of LIF neurons.\n",
      "u : float, list, numpy.ndarray, optional\n",
      "    Initial value of the neurons' current.\n",
      "v : float, list, numpy.ndarray, optional\n",
      "    Initial value of the neurons' voltage (membrane potential).\n",
      "du : float, optional\n",
      "    Inverse of decay time-constant for current decay. Currently, only a\n",
      "    single decay can be set for the entire population of neurons.\n",
      "dv : float, optional\n",
      "    Inverse of decay time-constant for voltage decay. Currently, only a\n",
      "    single decay can be set for the entire population of neurons.\n",
      "bias_mant : float, list, numpy.ndarray, optional\n",
      "    Mantissa part of neuron bias.\n",
      "bias_exp : float, list, numpy.ndarray, optional\n",
      "    Exponent part of neuron bias, if needed. Mostly for fixed point\n",
      "    implementations. Ignored for floating point implementations.\n",
      "vth : float, optional\n",
      "    Neuron threshold voltage, exceeding which, the neuron will spike.\n",
      "    Currently, only a single threshold can be set for the entire\n",
      "    population of neurons.\n",
      "\n",
      "Example\n",
      "-------\n",
      ">>> lif = LIF(shape=(200, 15), du=10, dv=5)\n",
      "This will create 200x15 LIF neurons that all have the same current decay\n",
      "of 10 and voltage decay of 5.\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initializes a new Process.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Desktop/feup/thesis/thesis-lava/src/lava/proc/lif/process.py\n",
      "\u001b[0;31mType:\u001b[0m           ProcessPostInitCaller\n",
      "\u001b[0;31mSubclasses:\u001b[0m     LIFReset, LIFRefractory"
     ]
    }
   ],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense\n",
    "import numpy as np\n",
    "\n",
    "LIF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check WD (change if necessary) and file loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/monkin/Desktop/feup/thesis/thesis-lava/src/hfo/snn\n"
     ]
    }
   ],
   "source": [
    "# Show current directory\n",
    "import os\n",
    "curr_dir = os.getcwd()\n",
    "print(curr_dir)\n",
    "\n",
    "# Check if the current WD is the file location\n",
    "if \"/src/hfo/snn\" not in os.getcwd():\n",
    "    # Set working directory to this file location\n",
    "    file_location = f\"{os.getcwd()}/thesis-lava/src/hfo/snn\"\n",
    "    print(\"File Location: \", file_location)\n",
    "\n",
    "    # Change the current working Directory\n",
    "    os.chdir(file_location)\n",
    "\n",
    "    # New Working Directory\n",
    "    print(\"New Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Custom Input Layer\n",
    "\n",
    "### Define function to read the input data from the csv file and generate the corresponding spike events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_spike_events(file_path: str):\n",
    "    \"\"\"Reads the spike events from the input file and returns them as a numpy array\n",
    "\n",
    "    Args:\n",
    "        file_path (str): name of the file containing the spike events\n",
    "    \"\"\"\n",
    "    spike_events = []\n",
    "\n",
    "    try:\n",
    "        # Read the spike events from the file\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "        # Detect errors\n",
    "        if df.empty:\n",
    "            raise Exception(\"The input file is empty\")\n",
    "\n",
    "        # Convert the scientific notation values to integers if any exist\n",
    "        df = df.applymap(lambda x: int(float(x)) if (isinstance(x, str) and 'e' in x) else x)\n",
    "\n",
    "        # Convert the dataframe to a numpy array\n",
    "        spike_events = df.to_numpy()\n",
    "        return spike_events[0]\n",
    "    except Exception as e:\n",
    "        print(\"Unable to read the input file: \", file_path, \" error:\", e)\n",
    "\n",
    "    return spike_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the UP and DOWN spikes from the CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spike Events Shape: (198, 2).\n",
      "Preview: [[1.00537109e+03 6.30000000e+01]\n",
      " [1.00878906e+03 6.30000000e+01]\n",
      " [1.01220703e+03 6.30000000e+01]\n",
      " [1.01269531e+03 6.30000000e+01]\n",
      " [1.01611328e+03 6.30000000e+01]\n",
      " ...\n",
      " [1.14575684e+05 6.30000000e+01]\n",
      " [1.14576172e+05 6.30000000e+01]\n",
      " [1.14579102e+05 6.30000000e+01]\n",
      " [1.14582520e+05 6.30000000e+01]\n",
      " [1.14585938e+05 6.30000000e+01]]\n",
      "Spike Events Shape: (196, 2).\n",
      "Preview: [[1.00439453e+03 6.30000000e+01]\n",
      " [1.00732422e+03 6.30000000e+01]\n",
      " [1.01123047e+03 6.30000000e+01]\n",
      " [1.01416016e+03 6.30000000e+01]\n",
      " [1.01806641e+03 6.30000000e+01]\n",
      " ...\n",
      " [1.14574219e+05 6.30000000e+01]\n",
      " [1.14574707e+05 6.30000000e+01]\n",
      " [1.14577637e+05 6.30000000e+01]\n",
      " [1.14581055e+05 6.30000000e+01]\n",
      " [1.14584961e+05 6.30000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "from utils.input import read_spike_events\n",
    "from utils.io import preview_np_array\n",
    "\n",
    "# Call the function to read the spike events\n",
    "up_spikes_file_path = \"./data/fr_up_spike_train_3.csv\"\n",
    "up_spike_train = read_spike_events(up_spikes_file_path)\n",
    "\n",
    "down_spikes_file_path = \"./data/fr_down_spike_train_-3.csv\"\n",
    "down_spike_train = read_spike_events(down_spikes_file_path)\n",
    "\n",
    "preview_np_array(up_spike_train, \"Spike Events\")\n",
    "preview_np_array(down_spike_train, \"Spike Events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the SpikeEvent Generator Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import OutPort\n",
    "\n",
    "class SpikeEventGen(AbstractProcess):\n",
    "    \"\"\"Input Process that generates spike events based on the input file\n",
    "\n",
    "    Args:\n",
    "        @shape (tuple): Shape of the output port\n",
    "        @exc_spike_events (np.ndarray): Excitatory spike events\n",
    "        @inh_spike_event (np.ndarray): Inhibitory spike events\n",
    "        @name (str): Name of the process\n",
    "    \"\"\"\n",
    "    def __init__(self, shape: tuple, exc_spike_events: np.ndarray, inh_spike_event: np.ndarray, name: str) -> None:\n",
    "        super().__init__(name=name)\n",
    "        self.s_out = OutPort(shape=shape)\n",
    "        self.exc_spike_events = Var(shape=exc_spike_events.shape, init=exc_spike_events)\n",
    "        self.inh_spike_events = Var(shape=inh_spike_event.shape, init=inh_spike_event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Architecture of the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in each LIF Layer\n",
    "n1 = 256   # 256 neurons in the first layer\n",
    "# n2 = 1  # 1 neuron in the second layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the LIF Models to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_refractory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LIF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for the LIF Process\n",
    "v_th = 1\n",
    "v_init = 0\n",
    "\n",
    "# LIF1 Process\n",
    "dv1 = 0.14\n",
    "du1 = 0.2  \n",
    "\n",
    "# LIF2 Process\n",
    "dv2 = 0.1\n",
    "du2 = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LIF Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_refractory:\n",
    "    # Create LIF1 process\n",
    "    lif1 = LIF(shape=(n1,),  # There are 2 neurons\n",
    "            vth=v_th,  # TODO: Verify these initial values\n",
    "            v=v_init,\n",
    "            dv=dv1,    # Inverse of decay time-constant for voltage decay\n",
    "            du=du1,  # Inverse of decay time-constant for current decay\n",
    "            bias_mant=0,\n",
    "            bias_exp=0,\n",
    "            name=\"lif1\")\n",
    "\n",
    "    # TODO: Check if we need to change the dynamics of the LIF2 process\n",
    "    # Create LIF2 process\n",
    "    \"\"\" lif2 = LIF(shape=(n2,),  # There is 1 neuron\n",
    "            vth=v_th,  # TODO: Verify these initial values\n",
    "            v=v_init,\n",
    "            dv=dv2,    # Inverse of decay time-constant for voltage decay\n",
    "            du=du2,  # Inverse of decay time-constant for current decay\n",
    "            bias_mant=0,\n",
    "            bias_exp=0,\n",
    "            name=\"lif2\") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Refractory LIF Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIFRefractory\n",
    "from lava.magma.core.process.process import LogConfig\n",
    "import logging\n",
    "\n",
    "# Constants for the Refractory LIF Process\n",
    "refrac_period = 20   # Number of time-steps for the refractory period\n",
    "\n",
    "if use_refractory:\n",
    "    # Create Refractory LIF1 process\n",
    "    lif1 = LIFRefractory(shape=(n1,),  # There are 2 neurons\n",
    "            vth=v_th,  # TODO: Verify these initial values\n",
    "            v=v_init,\n",
    "            dv=dv1,    # Inverse of decay time-constant for voltage decay\n",
    "            du=du1,  # Inverse of decay time-constant for current decay\n",
    "            bias_mant=0,\n",
    "            bias_exp=0,\n",
    "            refractory_period=refrac_period,\n",
    "            name=\"lif1\",\n",
    "            # log_config=LogConfig(level=logging.DEBUG, level_console=logging.DEBUG, logs_to_file=False)\n",
    "            )\n",
    "\n",
    "    # TODO: Check if we need to change the dynamics of the LIF2 process\n",
    "    # Create Refractory LIF2 process\n",
    "    lif2 = LIFRefractory(shape=(n2,),  # There is 1 neuron\n",
    "            vth=v_th,  # TODO: Verify these initial values\n",
    "            v=v_init,\n",
    "            dv=dv2,    # Inverse of decay time-constant for voltage decay\n",
    "            du=du2,  # Inverse of decay time-constant for current decay\n",
    "            bias_mant=0,\n",
    "            bias_exp=0,\n",
    "            refractory_period=refrac_period,\n",
    "            name=\"lif2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dense_weights_middle = np.ones(shape=(n2, n1))\\n# multiply the weights of the Dense layer by a constant\\nweights_scale_middle = 0.15     # This value is chosen to sum the inputs from all neurons in LIF1\\n# dense_weights_middle *= weights_scale_input     # Multiply by the same constant as the input layer to keep the same dynamics as LIF1\\ndense_weights_middle *= weights_scale_middle    # Multiply by a new constant to sum the inputs from all neurons in LIF1\\n# Create Dense Process to connect the two LIF layers\\ndense_middle = Dense(shape=(n1, n2),  # There are 2 neurons in the first layer and 1 in the second\\n              weights=np.array(dense_weights_middle),  # TODO: Check these weights\\n              name=\"Dense_LIF1-2\") '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dense Process to connect the input layer and LIF1\n",
    "# create weights of the dense layer\n",
    "dense_weights_input = np.eye(N=n1, M=n1)\n",
    "# multiply the weights of the Dense layer by a constant\n",
    "weights_scale_input = 0.13\n",
    "dense_weights_input *= weights_scale_input\n",
    "dense_input = Dense(weights=np.array(dense_weights_input), name=\"DenseInput\")\n",
    "\n",
    "\n",
    "# Create Dense Process to connect LIF1 and LIF2\n",
    "# create weights of the dense layer connecting LIF1 and LIF2\n",
    "\"\"\" dense_weights_middle = np.ones(shape=(n2, n1))\n",
    "# multiply the weights of the Dense layer by a constant\n",
    "weights_scale_middle = 0.15     # This value is chosen to sum the inputs from all neurons in LIF1\n",
    "# dense_weights_middle *= weights_scale_input     # Multiply by the same constant as the input layer to keep the same dynamics as LIF1\n",
    "dense_weights_middle *= weights_scale_middle    # Multiply by a new constant to sum the inputs from all neurons in LIF1\n",
    "# Create Dense Process to connect the two LIF layers\n",
    "dense_middle = Dense(shape=(n1, n2),  # There are 2 neurons in the first layer and 1 in the second\n",
    "              weights=np.array(dense_weights_middle),  # TODO: Check these weights\n",
    "              name=\"Dense_LIF1-2\") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the input channels to the corresponding indexes in the input layer\n",
    "Since the input channels in the input file may be of any number, we need to **map the input channels to the corresponding indexes in the input layer**. This is done by the `channel_map` dictionaries.\n",
    "\n",
    "The network expects an UP and DOWN spike train for each channel. Thusly, let's define 2 dictionaries, one for the UP spikes and one for the DOWN spikes. We want the UP and DOWN spike trains to be followed by each other in the input layer for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the channels of the input file to the respective index in the output list of SpikeEventGen\n",
    "\n",
    "# Define the mapping of the channels of the UP spike train to the respective index in the output list of SpikeEventGen\n",
    "up_channel_map = {63: 0}\n",
    "# Define the mapping of the channels of the DOWN spike train to the respective index in the output list of SpikeEventGen\n",
    "down_channel_map = {63: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants related to the simulation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_offset = 0  # 33400      #   \n",
    "virtual_time_step_interval = 1\n",
    "\n",
    "num_steps = 300    # 200 # Number of steps to run the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the `SpikeEventGenerator` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.model.py.model import PyLoihiProcessModel  # Processes running on CPU inherit from this class\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.model.py.ports import PyOutPort\n",
    "\n",
    "@implements(proc=SpikeEventGen, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeEventGenModel(PyLoihiProcessModel):\n",
    "    \"\"\"Spike Event Generator Process implementation running on CPU (Python)\n",
    "    Args:\n",
    "    \"\"\"\n",
    "    s_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, float)   # IT IS POSSIBLE TO SEND FLOATS AFTER ALL\n",
    "    exc_spike_events: np.ndarray = LavaPyType(np.ndarray, np.ndarray)\n",
    "    inh_spike_events: np.ndarray = LavaPyType(np.ndarray, np.ndarray)\n",
    "\n",
    "    def __init__(self, proc_params) -> None:\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        # print(\"spike events\", self.spike_events.__str__())    # TODO: Check why during initialization the variable prints the class, while during run it prints the value\n",
    "        self.curr_exc_idx = 0     # Index of the next excitatory spiking event to send\n",
    "        self.curr_inh_idx = 0     # Index of the next inhibitory spiking event to send\n",
    "        self.virtual_time_step_interval = virtual_time_step_interval  # 1000    # Arbitrary time between time steps (in microseconds). This is not a real time interval (1000ms = 1s)\n",
    "        self.init_offset = init_offset        # 698995               # Arbitrary offset to start the simulation (in microseconds)\n",
    "\n",
    "    def run_spk(self) -> None:\n",
    "        spike_data = np.zeros(self.s_out.shape) # Initialize the spike data to 0\n",
    "        \n",
    "        #print(\"time step:\", self.time_step)\n",
    "\n",
    "        # If the current simulation time is greater than a spike event, send a spike in the corresponding channel\n",
    "        currTime = self.init_offset + self.time_step*self.virtual_time_step_interval\n",
    "\n",
    "        spiking_channels = set()   # List of channels that will spike in the current time step\n",
    "\n",
    "        # Add the excitatory spike events to the spike_date\n",
    "        while (self.curr_exc_idx < len(self.exc_spike_events)) and currTime >= self.exc_spike_events[self.curr_exc_idx][0]:\n",
    "            # Get the channel of the current spike event\n",
    "            curr_channel = self.exc_spike_events[self.curr_exc_idx][1]\n",
    "\n",
    "            # Check if the channel is valid (belongs to a channel in the up_channel_map therefore it has an output index)\n",
    "            if curr_channel not in up_channel_map:\n",
    "                self.curr_exc_idx += 1\n",
    "                continue    # Skip the current spike event\n",
    "\n",
    "            # Check if the next spike belongs to a channel that will already spike in this time step\n",
    "            # If so, we don't add the event and stop looking for more events\n",
    "            if curr_channel in spiking_channels:\n",
    "                break\n",
    "\n",
    "            # Add the channel to the list of spiking channels\n",
    "            spiking_channels.add(curr_channel)\n",
    "\n",
    "            # Get the output index of the current channel according to the up_channel_map\n",
    "            out_idx = up_channel_map[curr_channel]\n",
    "            if out_idx < self.s_out.shape[0]:   # Check if the channel is valid\n",
    "                # Update the spike_data with the excitatory spike event (value = 1.0)\n",
    "                spike_data[out_idx] = 1.0   # Send spike (value corresponds to the punctual current of the spike event)\n",
    "\n",
    "            # Move to the next spike event\n",
    "            self.curr_exc_idx += 1\n",
    "\n",
    "        # Add the inhibitory spike events to the spike_date\n",
    "        while (self.curr_inh_idx < len(self.inh_spike_events)) and currTime >= self.inh_spike_events[self.curr_inh_idx][0]:\n",
    "            # Get the channel of the current spike event\n",
    "            curr_channel = self.inh_spike_events[self.curr_inh_idx][1]\n",
    "\n",
    "            # Check if the channel is valid (belongs to a channel in the down_channel_map therefore it has an output index)\n",
    "            if curr_channel not in down_channel_map:\n",
    "                self.curr_inh_idx += 1\n",
    "                continue    # Skip the current spike event\n",
    "\n",
    "            # Check if the next spike belongs to a channel that will already spike in this time step\n",
    "            # If so, we don't add the event and stop looking for more events\n",
    "            if curr_channel in spiking_channels:\n",
    "                break\n",
    "\n",
    "            # Add the channel to the list of spiking channels\n",
    "            spiking_channels.add(curr_channel)\n",
    "\n",
    "            # Get the output index of the current channel according to the down_channel_map\n",
    "            out_idx = down_channel_map[curr_channel]\n",
    "            if out_idx < self.s_out.shape[0]:   # Check if the channel is valid\n",
    "                # Update the spike_data with the inhibitory spike event (value = -1.0)\n",
    "                spike_data[out_idx] = -1.0   # Send spike (value corresponds to the punctual current of the spike event)\n",
    "\n",
    "            # Move to the next spike event\n",
    "            self.curr_inh_idx += 1\n",
    "\n",
    "\n",
    "        if len(spiking_channels) > 0:   # Print the spike event if there are any spikes\n",
    "            print(f\"\"\"end=sending spike event at time: {currTime}({self.time_step}). Last Excitatory/Inhibitory spike idx: {self.curr_inh_idx-1}/{self.curr_inh_idx}\\n\n",
    "                  Spike times: {self.exc_spike_events[self.curr_inh_idx-1][0]}/{self.inh_spike_events[self.curr_inh_idx-1][0]} \\n \n",
    "                  spike_data: {spike_data}\"\"\")\n",
    "\n",
    "        # Send spikes\n",
    "        # print(\"sending spike_data: \", spike_data, \" at step: \", self.time_step)\n",
    "        self.s_out.send(spike_data)\n",
    "\n",
    "        # Stop the Process if there are no more spike events to send. (It will stop all the connected processes)\n",
    "        # TODO: Should it be another process that stops the simulation? Such as the last LIF process\n",
    "        # if self.curr_spike_idx >= 5: # len(self.spike_events):\n",
    "        #    self.pause()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect the Layers\n",
    "To define the connectivity between the `SpikeGenerator` and the first `LIF` population, we use another `Dense` Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Input Process\n",
    "spike_event_gen = SpikeEventGen(shape=(n1,), exc_spike_events=up_spike_train, inh_spike_event=down_spike_train, name=\"CustomInput\")\n",
    "\n",
    "# If I connect the SpikeEventGen to the Dense Layer, the a_out value of the custom input will be rounded to 0 or 1 in the Dense Layer (it will not be a float) \n",
    "# However, setting the Dense weights to a float works instead\n",
    "# Connect the SpikeEventGen to the Dense Layer\n",
    "spike_event_gen.s_out.connect(dense_input.s_in)\n",
    "\n",
    "# Connect the Dense_Input to the LIF1 Layer\n",
    "dense_input.a_out.connect(lif1.a_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the connections in the Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proc: CustomInput Port Name: s_out Size: 256\n",
      "Proc: DenseInput Port Name: s_in  Size: 256\n",
      "Proc: DenseInput Port Name: a_out Size: 256\n",
      "Proc: lif1  Port Name: a_in  Size: 256\n",
      "Proc: lif1  Port Name: s_out Size: 256\n"
     ]
    }
   ],
   "source": [
    "for proc in [spike_event_gen, dense_input, lif1]:\n",
    "    for port in proc.in_ports:\n",
    "        print(f\"Proc: {proc.name:<5} Port Name: {port.name:<5} Size: {port.size}\")\n",
    "    for port in proc.out_ports:\n",
    "        print(f\"Proc: {proc.name:<5} Port Name: {port.name:<5} Size: {port.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the weights of the Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13, 0.  , 0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.13, 0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.13, 0.  , 0.  , ..., 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.13, 0.  , ..., 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.13, ..., 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , ..., 0.13, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , ..., 0.  , 0.13, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.13, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  , 0.13, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.  , 0.  , 0.13]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights of the Input Dense Layer\n",
    "dense_input.weights.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Internal Vars over time\n",
    "To record the evolution of the internal variables over time, we need a `Monitor`. For this example, we want to record the membrane potential of the `LIF` Layer, hence we need 1 `Monitors`.\n",
    "\n",
    "We can define the `Var` that a `Monitor` should record, as well as the recording duration, using the `probe` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "\n",
    "monitor_lif1_v = Monitor()\n",
    "monitor_lif1_u = Monitor()\n",
    "\n",
    "# Connect the monitors to the variables we want to monitor\n",
    "monitor_lif1_v.probe(lif1.v, num_steps)\n",
    "monitor_lif1_u.probe(lif1.u, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "Now that we have defined the network, we can execute it. We will use the `run` function to execute the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Configuration and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.run_conditions import RunContinuous, RunSteps\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "# run_condition = RunContinuous()   # TODO: Change to this one\n",
    "run_condition = RunSteps(num_steps=num_steps)\n",
    "run_cfg = Loihi1SimCfg(select_tag=\"floating_pt\")   # TODO: Check why we need this select_tag=\"floating_pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif1.run(condition=run_condition, run_cfg=run_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve recorded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lif1_v = monitor_lif1_v.get_data()\n",
    "data_lif1_u = monitor_lif1_u.get_data()\n",
    "\n",
    "data_lif1 = data_lif1_v.copy()\n",
    "data_lif1[\"lif1\"][\"u\"] = data_lif1_u[\"lif1\"][\"u\"]   # Merge the dictionaries to contain both voltage and current\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.lif.process.LIF at 0x7f744bcd0670>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lif1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# Check the shape to verify if it is printing the voltage for every step\n",
    "print(len(data_lif1['lif1']['v']))     # Indeed, there are 300 values (same as the number of steps we ran the simulation for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the recorded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create a subplot for each monitored variable\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "ax0 = fig.add_subplot(221)\n",
    "ax0.set_title('Voltage (V) / time step')\n",
    "ax1 = fig.add_subplot(222)\n",
    "ax1.set_title('Current (U) / time step')\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "monitor_lif1_v.plot(ax0, lif1.v)\n",
    "monitor_lif1_u.plot(ax1, lif1.u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the timesteps where the network spiked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voltage Array Shape: (300, 256).\n",
      "Preview: [[0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0.]]\n",
      "Spike times LIF1:  []\n"
     ]
    }
   ],
   "source": [
    "from utils.data_analysis import find_spike_times\n",
    "\n",
    "voltage_arr_1 = np.array(data_lif1['lif1']['v'])\n",
    "preview_np_array(voltage_arr_1, \"Voltage Array\")\n",
    "\n",
    "# Call the find_spike_times util function that detects the spikes in a voltage array\n",
    "spike_times_lif1 = find_spike_times(voltage_arr_1, v_th)\n",
    "\n",
    "print(\"Spike times LIF1: \", spike_times_lif1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Voltage and Current dynamics with an interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the data from the recorded variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lif1 voltage shape: 300\n"
     ]
    }
   ],
   "source": [
    "# LIF1 variables\n",
    "lif1_voltage_vals = data_lif1['lif1']['v']\n",
    "lif1_current_vals = data_lif1['lif1']['u']\n",
    "\n",
    "print(\"lif1 voltage shape:\", len(lif1_voltage_vals))\n",
    "# print(\"voltage head: \", lif1_voltage_vals[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the values to be plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.line_plot import create_fig  # Import the function to create the figure\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "# Define the x and y values\n",
    "x = [val + init_offset for val in range(num_steps)]\n",
    "\n",
    "v_y1 = [val[0] for val in lif1_voltage_vals]\n",
    "v_y2 = [val[1] for val in lif1_voltage_vals]\n",
    "v_y3 = [val[2] for val in lif1_voltage_vals]\n",
    "v_y4 = [val[3] for val in lif1_voltage_vals]\n",
    "v_y5 = [val[4] for val in lif1_voltage_vals]\n",
    "\n",
    "# Create the plot\n",
    "voltage_lif1_y_arrays = [(v_y1, \"Ch. 1\"), (v_y2, \"Ch. 2\"), (v_y3, \"Ch. 3\"),\n",
    "                          (v_y4, \"Ch. 4\"), (v_y5, \"Ch. 5\")]    # List of tuples containing the y values and the legend label\n",
    "# Define the box annotation parameters\n",
    "box_annotation_voltage = {\n",
    "    \"bottom\": 0,\n",
    "    \"top\": v_th,\n",
    "    \"left\": 0,\n",
    "    \"right\": num_steps,\n",
    "    \"fill_alpha\": 0.03,\n",
    "    \"fill_color\": \"green\"\n",
    "}\n",
    "\n",
    "# Create the LIF1 Voltage\n",
    "voltage_lif1_plot = create_fig(\n",
    "    title=\"LIF1 Voltage dynamics\", \n",
    "    x_axis_label='time (ms)', \n",
    "    y_axis_label='Voltage (V)',\n",
    "    x=x, \n",
    "    y_arrays=voltage_lif1_y_arrays, \n",
    "    sizing_mode=\"stretch_both\", \n",
    "    tools=\"pan, box_zoom, wheel_zoom, hover, undo, redo, zoom_in, zoom_out, reset, save\",\n",
    "    tooltips=\"Data point @x: @y\",\n",
    "    legend_location=\"top_right\",\n",
    "    legend_bg_fill_color=\"navy\",\n",
    "    legend_bg_fill_alpha=0.1,\n",
    "    box_annotation_params=box_annotation_voltage,\n",
    "    y_range=Range1d(-0.05, 1.05)\n",
    ")\n",
    "\n",
    "\n",
    "# Create the LIF1 Current\n",
    "u_y1 = [val[0] for val in lif1_current_vals]\n",
    "u_y2 = [val[1] for val in lif1_current_vals]\n",
    "u_y3 = [val[2] for val in lif1_current_vals]\n",
    "u_y4 = [val[3] for val in lif1_current_vals]\n",
    "u_y5 = [val[4] for val in lif1_current_vals]\n",
    "current_lif1_y_arrays = [(u_y1, \"Ch. 1\"), (u_y2, \"Ch. 2\"), (u_y3, \"Ch. 3\"),\n",
    "                          (u_y4, \"Ch. 4\"), (u_y5, \"Ch. 5\")]    # List of tuples containing the y values and the legend label\n",
    "current_lif1_plot = create_fig(\n",
    "    title=\"LIF1 Current dynamics\", \n",
    "    x_axis_label='time (ms)', \n",
    "    y_axis_label='Current (U)',\n",
    "    x=x, \n",
    "    y_arrays=current_lif1_y_arrays, \n",
    "    sizing_mode=\"stretch_both\", \n",
    "    tools=\"pan, box_zoom, wheel_zoom, hover, undo, redo, zoom_in, zoom_out, reset, save\",\n",
    "    tooltips=\"Data point @x: @y\",\n",
    "    legend_location=\"top_right\",\n",
    "    legend_bg_fill_color=\"navy\",\n",
    "    legend_bg_fill_alpha=0.1,\n",
    "    x_range=voltage_lif1_plot.x_range,    # Link the x-axis range to the voltage plot\n",
    ")\n",
    "\n",
    "# bplt.show(voltage_lif1_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Plots assembled in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.plotting as bplt\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "showPlot = True\n",
    "if showPlot:\n",
    "    # Create array of plots to be shown\n",
    "    plots = [voltage_lif1_plot, current_lif1_plot]\n",
    "\n",
    "    if len(plots) == 1:\n",
    "        grid = plots[0]\n",
    "    else:   # Create a grid layout\n",
    "        grid = gridplot(plots, ncols=2, sizing_mode=\"stretch_both\")\n",
    "\n",
    "    # Show the plot\n",
    "    bplt.show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the plot to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = False\n",
    "\n",
    "if export:\n",
    "    file_path = \"./results/lab_net_burst_5channels_3spikes_20ms_20refrac_0.15w_0.14_0.2_0.1_0.15.html\"\n",
    "\n",
    "    # Customize the output file settings\n",
    "    bplt.output_file(filename=file_path, title=\"Network Burst detection - Voltage and Current dynamics\")\n",
    "\n",
    "    # Save the plot\n",
    "    bplt.save(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
